{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14858ab-f05c-4c74-8fa7-7c8ffb96eb2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AutoGluon Tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372ab77-37ac-4898-a956-14471faf9b5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Essential\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1621d07-a5f3-4d8a-a962-23eb2d7cd350",
   "metadata": {},
   "source": [
    "### library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547b2952-0e87-4632-bf91-f489de0b9672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204ffa7-314a-4d4b-82d2-780c82b20aeb",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af36ba1-b480-4b5b-a3fb-671262863b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8297e14a-69b2-48ce-ad65-d1cabd9f1467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b76f4-a31a-4245-964b-c4f0f6c37df0",
   "metadata": {},
   "source": [
    "### predictor, fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9481a311-5498-4224-9f47-96bbbddd5589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictClass/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8133.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.28s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40a3476-7a32-4ac7-aa32-927e47cdd4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0             0             0              20   United-States  \n",
       "1             0             0              45   United-States  \n",
       "2             0          1887              60   United-States  \n",
       "3             0             0              30   United-States  \n",
       "4             0             0              20   United-States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9a9663-fa98-4992-b382-e2b620f690ef",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b631af4-953c-4965-9e23-22a884ec3904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8397993653393387\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8397993653393387,\n",
      "    \"balanced_accuracy\": 0.7437076677780596,\n",
      "    \"mcc\": 0.5295565206264157,\n",
      "    \"f1\": 0.6242496998799519,\n",
      "    \"precision\": 0.7038440714672441,\n",
      "    \"recall\": 0.5608283002588438\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " 0        <=50K\n",
      "1        <=50K\n",
      "2         >50K\n",
      "3        <=50K\n",
      "4        <=50K\n",
      "         ...  \n",
      "9764     <=50K\n",
      "9765     <=50K\n",
      "9766     <=50K\n",
      "9767     <=50K\n",
      "9768     <=50K\n",
      "Name: class, Length: 9769, dtype: object\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cef013-7091-4cb9-a185-e7dfff61cc54",
   "metadata": {},
   "source": [
    "### leader board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b0ab7c-83d3-42fd-9af7-981f1edd7997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.214266</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.214266</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.070275</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.331338</td>\n",
       "      <td>0.070275</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.331338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.180476</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.180476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.369218</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.369218</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.528940</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.159722</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.577779</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.577779</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.067526</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.177546</td>\n",
       "      <td>0.067526</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.177546</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>1.342726</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>1.342726</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.824035</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.614711</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.614711</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.049568</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.526530</td>\n",
       "      <td>0.049568</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.526530</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>0.674374</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>0.674374</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              CatBoost    0.842461       0.85        0.008160       0.002433   \n",
       "1               XGBoost    0.842461       0.85        0.015381       0.002221   \n",
       "2      RandomForestGini    0.842461       0.84        0.070275       0.014841   \n",
       "3      RandomForestEntr    0.840925       0.83        0.065891       0.014404   \n",
       "4              LightGBM    0.839799       0.85        0.014113       0.002041   \n",
       "5   WeightedEnsemble_L2    0.839799       0.85        0.016190       0.002314   \n",
       "6            LightGBMXT    0.836421       0.83        0.007182       0.002296   \n",
       "7        ExtraTreesGini    0.834374       0.82        0.067526       0.015412   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.065272       0.014964   \n",
       "9         LightGBMLarge    0.828949       0.83        0.016615       0.002345   \n",
       "10       NeuralNetTorch    0.824035       0.84        0.028923       0.004084   \n",
       "11      NeuralNetFastAI    0.823626       0.82        0.049568       0.007399   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.010722       0.012619   \n",
       "13       KNeighborsDist    0.695158       0.65        0.008772       0.002233   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.702048                 0.008160                0.002433   \n",
       "1   0.214266                 0.015381                0.002221   \n",
       "2   0.331338                 0.070275                0.014841   \n",
       "3   0.180476                 0.065891                0.014404   \n",
       "4   0.369218                 0.014113                0.002041   \n",
       "5   0.528940                 0.002077                0.000273   \n",
       "6   0.577779                 0.007182                0.002296   \n",
       "7   0.177546                 0.067526                0.015412   \n",
       "8   0.176079                 0.065272                0.014964   \n",
       "9   1.342726                 0.016615                0.002345   \n",
       "10  0.614711                 0.028923                0.004084   \n",
       "11  0.526530                 0.049568                0.007399   \n",
       "12  0.674374                 0.010722                0.012619   \n",
       "13  0.003176                 0.008772                0.002233   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.702048            1       True          7  \n",
       "1            0.214266            1       True         11  \n",
       "2            0.331338            1       True          5  \n",
       "3            0.180476            1       True          6  \n",
       "4            0.369218            1       True          4  \n",
       "5            0.159722            2       True         14  \n",
       "6            0.577779            1       True          3  \n",
       "7            0.177546            1       True          8  \n",
       "8            0.176079            1       True          9  \n",
       "9            1.342726            1       True         13  \n",
       "10           0.614711            1       True         12  \n",
       "11           0.526530            1       True         10  \n",
       "12           0.674374            1       True          1  \n",
       "13           0.003176            1       True          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c053c-2567-4623-ae3d-ae159abd37cd",
   "metadata": {},
   "source": [
    "### predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba41e0c-3b13-4c7f-a945-a14883382e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949797</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945973</td>\n",
       "      <td>0.054027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.433299</td>\n",
       "      <td>0.566701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.991393</td>\n",
       "      <td>0.008607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.949908</td>\n",
       "      <td>0.050092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      <=50K      >50K\n",
       "0  0.949797  0.050203\n",
       "1  0.945973  0.054027\n",
       "2  0.433299  0.566701\n",
       "3  0.991393  0.008607\n",
       "4  0.949908  0.050092"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = predictor.predict_proba(test_data_nolab)\n",
    "pred_probs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffe806-9f2e-4e98-aed5-e8309fc0a949",
   "metadata": {},
   "source": [
    "### fit_summary\n",
    "\n",
    "we can see many different types of models performing results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a5ff15-bef8-4058-ba12-ec1f132e1384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0              LightGBM       0.85       0.002041  0.369218                0.002041           0.369218            1       True          4\n",
      "1               XGBoost       0.85       0.002221  0.214266                0.002221           0.214266            1       True         11\n",
      "2   WeightedEnsemble_L2       0.85       0.002314  0.528940                0.000273           0.159722            2       True         14\n",
      "3              CatBoost       0.85       0.002433  0.702048                0.002433           0.702048            1       True          7\n",
      "4        NeuralNetTorch       0.84       0.004084  0.614711                0.004084           0.614711            1       True         12\n",
      "5      RandomForestGini       0.84       0.014841  0.331338                0.014841           0.331338            1       True          5\n",
      "6            LightGBMXT       0.83       0.002296  0.577779                0.002296           0.577779            1       True          3\n",
      "7         LightGBMLarge       0.83       0.002345  1.342726                0.002345           1.342726            1       True         13\n",
      "8      RandomForestEntr       0.83       0.014404  0.180476                0.014404           0.180476            1       True          6\n",
      "9       NeuralNetFastAI       0.82       0.007399  0.526530                0.007399           0.526530            1       True         10\n",
      "10       ExtraTreesGini       0.82       0.015412  0.177546                0.015412           0.177546            1       True          8\n",
      "11       ExtraTreesEntr       0.81       0.014964  0.176079                0.014964           0.176079            1       True          9\n",
      "12       KNeighborsUnif       0.73       0.012619  0.674374                0.012619           0.674374            1       True          1\n",
      "13       KNeighborsDist       0.65       0.002233  0.003176                0.002233           0.003176            1       True          2\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'KNNModel', 'NNFastAiTabularModel', 'TabularNeuralNetTorchModel', 'RFModel', 'WeightedEnsembleModel', 'LGBModel', 'CatBoostModel', 'XGBoostModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: agModels-predictClass/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8ce22-b958-4e0c-90d1-ca45251360d2",
   "metadata": {},
   "source": [
    "### type check\n",
    "\n",
    "> problem type<br>\n",
    "> feature type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df4c6bf-2b3e-4205-bb34-cb0ad0178b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfcfbb6-4ef8-4c77-b0ef-fb37fb44e431",
   "metadata": {},
   "source": [
    "### specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad699da-6f0f-4503-b829-19b36e3496b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.214266</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.214266</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.069004</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.331338</td>\n",
       "      <td>0.069004</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.331338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.064986</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.180476</td>\n",
       "      <td>0.064986</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.180476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.369218</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.369218</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.528940</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.159722</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.577779</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.577779</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.067059</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.177546</td>\n",
       "      <td>0.067059</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.177546</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.066861</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>0.066861</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017103</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>1.342726</td>\n",
       "      <td>0.017103</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>1.342726</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.824035</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.026772</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.614711</td>\n",
       "      <td>0.026772</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.614711</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.526530</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.526530</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>0.674374</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>0.674374</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              CatBoost    0.842461       0.85        0.007754       0.002433   \n",
       "1               XGBoost    0.842461       0.85        0.016167       0.002221   \n",
       "2      RandomForestGini    0.842461       0.84        0.069004       0.014841   \n",
       "3      RandomForestEntr    0.840925       0.83        0.064986       0.014404   \n",
       "4              LightGBM    0.839799       0.85        0.015015       0.002041   \n",
       "5   WeightedEnsemble_L2    0.839799       0.85        0.016686       0.002314   \n",
       "6            LightGBMXT    0.836421       0.83        0.006282       0.002296   \n",
       "7        ExtraTreesGini    0.834374       0.82        0.067059       0.015412   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.066861       0.014964   \n",
       "9         LightGBMLarge    0.828949       0.83        0.017103       0.002345   \n",
       "10       NeuralNetTorch    0.824035       0.84        0.026772       0.004084   \n",
       "11      NeuralNetFastAI    0.823626       0.82        0.049611       0.007399   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.009291       0.012619   \n",
       "13       KNeighborsDist    0.695158       0.65        0.009130       0.002233   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.702048                 0.007754                0.002433   \n",
       "1   0.214266                 0.016167                0.002221   \n",
       "2   0.331338                 0.069004                0.014841   \n",
       "3   0.180476                 0.064986                0.014404   \n",
       "4   0.369218                 0.015015                0.002041   \n",
       "5   0.528940                 0.001671                0.000273   \n",
       "6   0.577779                 0.006282                0.002296   \n",
       "7   0.177546                 0.067059                0.015412   \n",
       "8   0.176079                 0.066861                0.014964   \n",
       "9   1.342726                 0.017103                0.002345   \n",
       "10  0.614711                 0.026772                0.004084   \n",
       "11  0.526530                 0.049611                0.007399   \n",
       "12  0.674374                 0.009291                0.012619   \n",
       "13  0.003176                 0.009130                0.002233   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.702048            1       True          7  \n",
       "1            0.214266            1       True         11  \n",
       "2            0.331338            1       True          5  \n",
       "3            0.180476            1       True          6  \n",
       "4            0.369218            1       True          4  \n",
       "5            0.159722            2       True         14  \n",
       "6            0.577779            1       True          3  \n",
       "7            0.177546            1       True          8  \n",
       "8            0.176079            1       True          9  \n",
       "9            1.342726            1       True         13  \n",
       "10           0.614711            1       True         12  \n",
       "11           0.526530            1       True         10  \n",
       "12           0.674374            1       True          1  \n",
       "13           0.003176            1       True          2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427ac1ce-f309-4c12-aa4b-6f692ca39774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2        <=50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_data, model='LightGBMXT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c89c4-e68a-455e-befe-58c8db17d74e",
   "metadata": {},
   "source": [
    "### Presets\n",
    "- best_quality\n",
    "- high_quality\n",
    "- good_quality\n",
    "- medium_quality (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926256b-b672-4e2b-9671-8ed74f2fc659",
   "metadata": {},
   "source": [
    "### maximizing predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d80f8c-1efc-4fd2-ac5c-f9bbdb186a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_072846/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_072846/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7737.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.94s of the 59.94s of remaining time.\n",
      "\t0.5196\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.93s of the 59.93s of remaining time.\n",
      "\t0.537\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 59.92s of the 59.92s of remaining time.\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8819\t = Validation score   (roc_auc)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 59.15s of the 59.15s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.867\t = Validation score   (roc_auc)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 58.23s of the 58.23s of remaining time.\n",
      "\t0.8869\t = Validation score   (roc_auc)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 57.98s of the 57.98s of remaining time.\n",
      "\t0.8893\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 57.76s of the 57.76s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8907\t = Validation score   (roc_auc)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 53.55s of the 53.54s of remaining time.\n",
      "\t0.8931\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 53.31s of the 53.31s of remaining time.\n",
      "\t0.8875\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 53.09s of the 53.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8723\t = Validation score   (roc_auc)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 51.89s of the 51.89s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.869\t = Validation score   (roc_auc)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 51.21s of the 51.21s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8479\t = Validation score   (roc_auc)\n",
      "\t1.92s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 49.25s of the 49.25s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8433\t = Validation score   (roc_auc)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 47.42s of the 47.42s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.89\t = Validation score   (roc_auc)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 46.66s of the 46.66s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.877\t = Validation score   (roc_auc)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 45.82s of the 45.82s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8966\t = Validation score   (roc_auc)\n",
      "\t8.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 41.72s of the 41.72s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8893\t = Validation score   (roc_auc)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 40.51s of the 40.51s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8793\t = Validation score   (roc_auc)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 39.81s of the 39.81s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8599\t = Validation score   (roc_auc)\n",
      "\t4.66s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 37.04s of the 37.04s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.858\t = Validation score   (roc_auc)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 35.24s of the 35.24s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8905\t = Validation score   (roc_auc)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 34.57s of the 34.57s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8795\t = Validation score   (roc_auc)\n",
      "\t2.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 33.73s of the 33.73s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8948\t = Validation score   (roc_auc)\n",
      "\t11.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 30.0s of the 30.0s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8943\t = Validation score   (roc_auc)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 28.76s of the 28.76s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.878\t = Validation score   (roc_auc)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 28.07s of the 28.07s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8605\t = Validation score   (roc_auc)\n",
      "\t7.06s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 25.64s of the 25.64s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8594\t = Validation score   (roc_auc)\n",
      "\t5.24s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 23.94s of the 23.93s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8914\t = Validation score   (roc_auc)\n",
      "\t2.69s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 23.31s of the 23.31s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8805\t = Validation score   (roc_auc)\n",
      "\t3.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 22.52s of the 22.52s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8957\t = Validation score   (roc_auc)\n",
      "\t15.99s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 18.5s of the 18.5s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8912\t = Validation score   (roc_auc)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 17.14s of the 17.14s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8803\t = Validation score   (roc_auc)\n",
      "\t2.57s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 16.55s of the 16.55s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8646\t = Validation score   (roc_auc)\n",
      "\t9.16s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 14.41s of the 14.41s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8615\t = Validation score   (roc_auc)\n",
      "\t7.23s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Completed 4/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.94s of the 12.39s of remaining time.\n",
      "\t0.9053\t = Validation score   (roc_auc)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 47.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_072846/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.901743</td>\n",
       "      <td>0.895728</td>\n",
       "      <td>0.156766</td>\n",
       "      <td>0.041657</td>\n",
       "      <td>15.987669</td>\n",
       "      <td>0.156766</td>\n",
       "      <td>0.041657</td>\n",
       "      <td>15.987669</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.900042</td>\n",
       "      <td>0.891385</td>\n",
       "      <td>0.290548</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>2.688380</td>\n",
       "      <td>0.290548</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>2.688380</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.896692</td>\n",
       "      <td>0.905327</td>\n",
       "      <td>1.645161</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>24.172973</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.893014</td>\n",
       "      <td>0.880304</td>\n",
       "      <td>0.401158</td>\n",
       "      <td>0.038149</td>\n",
       "      <td>2.568441</td>\n",
       "      <td>0.401158</td>\n",
       "      <td>0.038149</td>\n",
       "      <td>2.568441</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.891950</td>\n",
       "      <td>0.880528</td>\n",
       "      <td>0.187948</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>3.275766</td>\n",
       "      <td>0.187948</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>3.275766</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.886841</td>\n",
       "      <td>0.889264</td>\n",
       "      <td>0.067833</td>\n",
       "      <td>0.036116</td>\n",
       "      <td>0.179776</td>\n",
       "      <td>0.067833</td>\n",
       "      <td>0.036116</td>\n",
       "      <td>0.179776</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.886591</td>\n",
       "      <td>0.864576</td>\n",
       "      <td>0.474017</td>\n",
       "      <td>0.078949</td>\n",
       "      <td>9.155463</td>\n",
       "      <td>0.474017</td>\n",
       "      <td>0.078949</td>\n",
       "      <td>9.155463</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.885065</td>\n",
       "      <td>0.886900</td>\n",
       "      <td>0.069668</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.203449</td>\n",
       "      <td>0.069668</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.203449</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.882790</td>\n",
       "      <td>0.891202</td>\n",
       "      <td>0.970134</td>\n",
       "      <td>0.081715</td>\n",
       "      <td>4.819302</td>\n",
       "      <td>0.970134</td>\n",
       "      <td>0.081715</td>\n",
       "      <td>4.819302</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.880534</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.176887</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.176887</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.879821</td>\n",
       "      <td>0.893090</td>\n",
       "      <td>0.079798</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>0.184804</td>\n",
       "      <td>0.079798</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>0.184804</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.874912</td>\n",
       "      <td>0.861512</td>\n",
       "      <td>0.264712</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>7.232139</td>\n",
       "      <td>0.264712</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>7.232139</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.525998</td>\n",
       "      <td>0.536956</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.519604</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0           CatBoost_BAG_L1    0.901743   0.895728        0.156766   \n",
       "1         LightGBMXT_BAG_L1    0.900042   0.891385        0.290548   \n",
       "2       WeightedEnsemble_L2    0.896692   0.905327        1.645161   \n",
       "3            XGBoost_BAG_L1    0.893014   0.880304        0.401158   \n",
       "4           LightGBM_BAG_L1    0.891950   0.880528        0.187948   \n",
       "5   RandomForestEntr_BAG_L1    0.886841   0.889264        0.067833   \n",
       "6     NeuralNetTorch_BAG_L1    0.886591   0.864576        0.474017   \n",
       "7   RandomForestGini_BAG_L1    0.885065   0.886900        0.069668   \n",
       "8    NeuralNetFastAI_BAG_L1    0.882790   0.891202        0.970134   \n",
       "9     ExtraTreesEntr_BAG_L1    0.880534   0.887519        0.075892   \n",
       "10    ExtraTreesGini_BAG_L1    0.879821   0.893090        0.079798   \n",
       "11     LightGBMLarge_BAG_L1    0.874912   0.861512        0.264712   \n",
       "12    KNeighborsDist_BAG_L1    0.525998   0.536956        0.009131   \n",
       "13    KNeighborsUnif_BAG_L1    0.514970   0.519604        0.009463   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.041657  15.987669                 0.156766                0.041657   \n",
       "1        0.050951   2.688380                 0.290548                0.050951   \n",
       "2        0.284655  24.172973                 0.002355                0.000170   \n",
       "3        0.038149   2.568441                 0.401158                0.038149   \n",
       "4        0.041250   3.275766                 0.187948                0.041250   \n",
       "5        0.036116   0.179776                 0.067833                0.036116   \n",
       "6        0.078949   9.155463                 0.474017                0.078949   \n",
       "7        0.036471   0.203449                 0.069668                0.036471   \n",
       "8        0.081715   4.819302                 0.970134                0.081715   \n",
       "9        0.036747   0.176887                 0.075892                0.036747   \n",
       "10       0.036945   0.184804                 0.079798                0.036945   \n",
       "11       0.041510   7.232139                 0.264712                0.041510   \n",
       "12       0.002167   0.001493                 0.009131                0.002167   \n",
       "13       0.005033   0.002359                 0.009463                0.005033   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           15.987669            1       True          7  \n",
       "1            2.688380            1       True          3  \n",
       "2            0.112481            2       True         14  \n",
       "3            2.568441            1       True         11  \n",
       "4            3.275766            1       True          4  \n",
       "5            0.179776            1       True          6  \n",
       "6            9.155463            1       True         12  \n",
       "7            0.203449            1       True          5  \n",
       "8            4.819302            1       True         10  \n",
       "9            0.176887            1       True          9  \n",
       "10           0.184804            1       True          8  \n",
       "11           7.232139            1       True         13  \n",
       "12           0.001493            1       True          2  \n",
       "13           0.002359            1       True          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fa687-5e91-499f-ae35-753ada2b5876",
   "metadata": {},
   "source": [
    "### Regression (predicting numeric table columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd1b89d1-1566-4373-a836-95c8b7fca58f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of age variable: \n",
      " count    500.00000\n",
      "mean      39.65200\n",
      "std       13.52393\n",
      "min       17.00000\n",
      "25%       29.00000\n",
      "50%       38.00000\n",
      "75%       49.00000\n",
      "max       85.00000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "age_column = 'age'\n",
    "print(\"Summary of age variable: \\n\", train_data[age_column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "512b12f5-eafa-482d-a309-847aa712652b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"agModels-predictAge/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: age\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (85, 17, 39.652, 13.52393)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7521.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 9 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 59.94s of the 59.94s of remaining time.\n",
      "\t-15.6869\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 59.93s of the 59.93s of remaining time.\n",
      "\t-15.1801\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.93s of the 59.93s of remaining time.\n",
      "\t-11.7092\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 59.71s of the 59.7s of remaining time.\n",
      "\t-11.9295\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 59.54s of the 59.54s of remaining time.\n",
      "\t-11.667\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 59.34s of the 59.34s of remaining time.\n",
      "\t-11.7993\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 58.84s of the 58.84s of remaining time.\n",
      "\t-11.3701\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 58.66s of the 58.66s of remaining time.\n",
      "\t-12.0823\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 58.38s of the 58.38s of remaining time.\n",
      "\t-12.261\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 58.13s of the 58.13s of remaining time.\n",
      "\t-11.5332\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 57.49s of the 57.49s of remaining time.\n",
      "\t-12.3153\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.94s of the 56.94s of remaining time.\n",
      "\t-11.1179\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictAge/\")\n",
      "/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1420: FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "  warnings.warn(\n",
      "Evaluation: root_mean_squared_error on test data: -10.518465489088348\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -10.518465489088348,\n",
      "    \"mean_squared_error\": -110.63811624514256,\n",
      "    \"mean_absolute_error\": -8.241263461535194,\n",
      "    \"r2\": 0.4086177916249283,\n",
      "    \"pearsonr\": 0.6396375085335058,\n",
      "    \"median_absolute_error\": -6.8641815185546875\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "predictor_age = TabularPredictor(label=age_column, path=\"agModels-predictAge\").fit(train_data, time_limit=60)\n",
    "performance = predictor_age.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e451a2d0-d99d-4395-872d-f46f9b3f3379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-10.518465</td>\n",
       "      <td>-11.117906</td>\n",
       "      <td>0.173487</td>\n",
       "      <td>0.030104</td>\n",
       "      <td>1.407216</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.100450</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-10.655822</td>\n",
       "      <td>-11.370142</td>\n",
       "      <td>0.054727</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.157286</td>\n",
       "      <td>0.054727</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.157286</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-10.745762</td>\n",
       "      <td>-11.666954</td>\n",
       "      <td>0.057256</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.179851</td>\n",
       "      <td>0.057256</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.179851</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-10.780312</td>\n",
       "      <td>-11.799279</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.491890</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.491890</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-10.837373</td>\n",
       "      <td>-11.709228</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.211336</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.211336</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-10.972156</td>\n",
       "      <td>-11.929546</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-11.076006</td>\n",
       "      <td>-12.261029</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.236305</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.236305</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-11.191017</td>\n",
       "      <td>-11.533245</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.632134</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.632134</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-11.382120</td>\n",
       "      <td>-12.082255</td>\n",
       "      <td>0.061360</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.278230</td>\n",
       "      <td>0.061360</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.278230</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-11.469922</td>\n",
       "      <td>-12.315314</td>\n",
       "      <td>0.026284</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.537697</td>\n",
       "      <td>0.026284</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.537697</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-14.902058</td>\n",
       "      <td>-15.686937</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-15.771259</td>\n",
       "      <td>-15.180149</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2  -10.518465 -11.117906        0.173487       0.030104   \n",
       "1         ExtraTreesMSE  -10.655822 -11.370142        0.054727       0.015389   \n",
       "2       RandomForestMSE  -10.745762 -11.666954        0.057256       0.015611   \n",
       "3              CatBoost  -10.780312 -11.799279        0.009914       0.002860   \n",
       "4            LightGBMXT  -10.837373 -11.709228        0.043940       0.002778   \n",
       "5              LightGBM  -10.972156 -11.929546        0.016594       0.001602   \n",
       "6               XGBoost  -11.076006 -12.261029        0.018151       0.002217   \n",
       "7        NeuralNetTorch  -11.191017 -11.533245        0.025506       0.004868   \n",
       "8       NeuralNetFastAI  -11.382120 -12.082255        0.061360       0.003926   \n",
       "9         LightGBMLarge  -11.469922 -12.315314        0.026284       0.002131   \n",
       "10       KNeighborsUnif  -14.902058 -15.686937        0.010599       0.003859   \n",
       "11       KNeighborsDist  -15.771259 -15.180149        0.011049       0.003552   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   1.407216                 0.002694                0.000152   \n",
       "1   0.157286                 0.054727                0.015389   \n",
       "2   0.179851                 0.057256                0.015611   \n",
       "3   0.491890                 0.009914                0.002860   \n",
       "4   0.211336                 0.043940                0.002778   \n",
       "5   0.156346                 0.016594                0.001602   \n",
       "6   0.236305                 0.018151                0.002217   \n",
       "7   0.632134                 0.025506                0.004868   \n",
       "8   0.278230                 0.061360                0.003926   \n",
       "9   0.537697                 0.026284                0.002131   \n",
       "10  0.003202                 0.010599                0.003859   \n",
       "11  0.002811                 0.011049                0.003552   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.100450            2       True         12  \n",
       "1            0.157286            1       True          7  \n",
       "2            0.179851            1       True          5  \n",
       "3            0.491890            1       True          6  \n",
       "4            0.211336            1       True          3  \n",
       "5            0.156346            1       True          4  \n",
       "6            0.236305            1       True          9  \n",
       "7            0.632134            1       True         10  \n",
       "8            0.278230            1       True          8  \n",
       "9            0.537697            1       True         11  \n",
       "10           0.003202            1       True          1  \n",
       "11           0.002811            1       True          2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_age.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d0189-f703-4a20-a4da-7adb3d4bdbf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## In depth\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/tabular-indepth.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23323e-79fb-40d7-9db1-6c772827ba52",
   "metadata": {},
   "source": [
    "\n",
    "- hyperparameter_tune_kwargs\n",
    "- hyperparameters\n",
    "- num_stack_levels\n",
    "- num_bag_folds\n",
    "- num_bag_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc3bc6-f64d-4d4e-8eec-9c8e46964d0e",
   "metadata": {},
   "source": [
    "### library and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edb18219-9445-44e9-8855-2268396aa39a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "6118              0             0              40   United-States    >50K  \n",
      "23204             0             0               8   United-States   <=50K  \n",
      "29590             0             0              44   United-States   <=50K  \n",
      "18116             0          2339              40     El-Salvador   <=50K  \n",
      "33964         15024             0              40   United-States    >50K  \n",
      "Summary of occupation column: \n",
      " count                  500\n",
      "unique                  15\n",
      "top        Exec-managerial\n",
      "freq                    77\n",
      "Name: occupation, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import numpy as np\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "print(train_data.head())\n",
    "\n",
    "label = 'occupation'\n",
    "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
    "\n",
    "new_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = new_data[5000:].copy()  # this should be separate data in your applications\n",
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label])  # delete label column\n",
    "val_data = new_data[:5000].copy()\n",
    "\n",
    "metric = 'accuracy' # we specify eval-metric just for demo (unnecessary as it's the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ab9fdc0-60d7-4bee-9ad2-bcd4c53eeb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Exec-managerial      77\n",
       " Craft-repair         67\n",
       " Sales                62\n",
       " Adm-clerical         57\n",
       " Prof-specialty       54\n",
       " Other-service        37\n",
       " Machine-op-inspct    35\n",
       " Transport-moving     27\n",
       " ?                    26\n",
       " Handlers-cleaners    24\n",
       " Tech-support         12\n",
       " Farming-fishing      11\n",
       " Protective-serv       9\n",
       " Armed-Forces          1\n",
       " Priv-house-serv       1\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[label].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6f703-49b2-4721-aad0-101a407f3d85",
   "metadata": {},
   "source": [
    "### specifying hyperparameters and tuning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4fb1319-ea97-4619-af7d-bcbf18a9c8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_074956/\"\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'hyperparameter_tune_kwargs': {'num_trials': 5,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'verbosity': 3}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 5,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Saving AutogluonModels/ag-20230606_074956/learner.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_074956/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Tuning Data Rows:    5000\n",
      "Tuning Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Performing general data preprocessing with merged train & validation data, so validation performance may not accurately reflect performance on new test data\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8488.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int64', 'int')     : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('object', 'object') : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\t\t('object', [])    : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t14 features in original data used to generate 14 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\t\t('object', [])    : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\t\t('object', [])    : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t14 features in original data used to generate 14 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t\t0.0s = Fit runtime\n",
      "\t\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', []) : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('int64', 'int')     : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', 'object') : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int64', 'int')         : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int8', 'int')          : 2 | ['sex', 'class']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.3 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving AutogluonModels/ag-20230606_074956/learner.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/utils/data/X.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/utils/data/y.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/utils/data/X_val.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBM: \t{'num_boost_round': 100, 'num_leaves': Int: lower=26, upper=66, 'ag_args': {'hyperparameter_tune_kwargs': {'num_trials': 5, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tNeuralNetTorch: \t{'num_epochs': 10, 'learning_rate': Real: lower=0.0001, upper=0.01, 'activation': Categorical['relu', 'softrelu', 'tanh'], 'dropout_prob': Real: lower=0.0, upper=0.5, 'ag_args': {'hyperparameter_tune_kwargs': {'num_trials': 5, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ... Tuning model for up to 53.96s of the 119.91s of remaining time.\n",
      "\tFitting LightGBM with 'num_gpus': 0, 'num_cpus': 8\n",
      "Starting generic AbstractModel hyperparameter tuning for LightGBM model...\n",
      "\tHyperparameter search space for LightGBM: \n",
      "learning_rate:   Real: lower=0.005, upper=0.2\n",
      "num_leaves:   Int: lower=26, upper=66\n",
      "feature_fraction:   Real: lower=0.75, upper=1.0\n",
      "min_data_in_leaf:   Int: lower=2, upper=60\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_train.pkl\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36c14a4b5434fc2aed2e5054b959ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_train.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_val.pkl\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.05, 'num_leaves': 36, 'feature_fraction': 1.0, 'min_data_in_leaf': 20}\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T1/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_train.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_val.pkl\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.06994332504138305, 'num_leaves': 29, 'feature_fraction': 0.8872033759818312, 'min_data_in_leaf': 5}\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T2/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_train.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_val.pkl\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.049883446878335284, 'num_leaves': 62, 'feature_fraction': 0.9618129346960314, 'min_data_in_leaf': 52}\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T3/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_train.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_val.pkl\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.006163502781172814, 'num_leaves': 27, 'feature_fraction': 0.824383651636118, 'min_data_in_leaf': 14}\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T4/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_train.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/dataset_val.pkl\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.035179640321040824, 'num_leaves': 43, 'feature_fraction': 0.9479312595206661, 'min_data_in_leaf': 26}\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T5/model.pkl\n",
      "Time for LightGBM model HPO: 3.3500001430511475\n",
      "Best hyperparameter configuration for LightGBM model: \n",
      "{'learning_rate': 0.049883446878335284, 'num_boost_round': 100, 'num_leaves': 62, 'feature_fraction': 0.9618129346960314, 'min_data_in_leaf': 52}\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T1/model.pkl\n",
      "Fitted model: LightGBM/T1 ...\n",
      "\t0.3033\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T2/model.pkl\n",
      "Fitted model: LightGBM/T2 ...\n",
      "\t0.2899\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T3/model.pkl\n",
      "Fitted model: LightGBM/T3 ...\n",
      "\t0.3238\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T4/model.pkl\n",
      "Fitted model: LightGBM/T4 ...\n",
      "\t0.2809\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T5/model.pkl\n",
      "Fitted model: LightGBM/T5 ...\n",
      "\t0.3108\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 53.96s of the 116.52s of remaining time.\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch model...\n",
      "\tHyperparameter search space for NeuralNetTorch: \n",
      "activation:   Categorical['relu', 'softrelu', 'tanh']\n",
      "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
      "dropout_prob:   Real: lower=0.0, upper=0.5\n",
      "learning_rate:   Real: lower=0.0001, upper=0.01\n",
      "weight_decay:   Real: lower=1e-12, upper=0.1\n",
      "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
      "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
      "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
      "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
      "num_layers:   Categorical[2, 3, 4]\n",
      "hidden_size:   Categorical[128, 256, 512]\n",
      "use_batchnorm:   Categorical[False, True]\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/NeuralNetTorch/dataset_train.pkl\n",
      "Saving /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/NeuralNetTorch/dataset_val.pkl\n",
      "Warning: Exception caused NeuralNetTorch to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1776, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1257, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1315, in _hyperparameter_tune\n",
      "    hpo_executor.execute(\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 375, in execute\n",
      "    analysis = run(\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/hpo/ray_hpo.py\", line 268, in run\n",
      "    tune.with_parameters(trainable, **trainable_args),\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 355, in with_parameters\n",
      "    parameter_registry.put(prefix + k, v)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/ray/tune/registry.py\", line 229, in put\n",
      "    self.flush()\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/ray/tune/registry.py\", line 241, in flush\n",
      "    self.references[k] = ray.put(v)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/ray/_private/worker.py\", line 2375, in put\n",
      "    object_ref = worker.put_object(value, owner_address=serialize_owner_address)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/ray/_private/worker.py\", line 619, in put_object\n",
      "    self.core_worker.put_serialized_object_and_increment_local_ref(\n",
      "  File \"python/ray/_raylet.pyx\", line 1708, in ray._raylet.CoreWorker.put_serialized_object_and_increment_local_ref\n",
      "  File \"python/ray/_raylet.pyx\", line 1597, in ray._raylet.CoreWorker._create_put_buffer\n",
      "  File \"python/ray/_raylet.pyx\", line 201, in ray._raylet.check_status\n",
      "ray.exceptions.RaySystemError: System error: Broken pipe\n",
      "System error: Broken pipe\n",
      "Saving AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T1/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T2/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T3/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T4/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T5/model.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.91s of the 116.28s of remaining time.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 47\n",
      "Ensemble weights: \n",
      "[0.08510638 0.04255319 0.70212766 0.04255319 0.12765957]\n",
      "Saving AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.3285\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 4.07s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Loading: AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/learner.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/predictor.pkl\n",
      "Saving AutogluonModels/ag-20230606_074956/__version__ with contents \"0.7.0\"\n",
      "Saving AutogluonModels/ag-20230606_074956/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_074956/\")\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "                }\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "                }\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 2*60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "                }\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, \n",
    "    eval_metric=metric\n",
    "    ).fit(\n",
    "        train_data, \n",
    "        tuning_data=val_data, #  ,       \n",
    "        time_limit=time_limit,\n",
    "        hyperparameters=hyperparameters, \n",
    "        hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "        verbosity=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dbe38b2-7ab3-4e31-855c-47961a12d8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T1/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T2/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T3/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T4/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T5/model.pkl\n",
      "Loading: AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T1/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T2/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T3/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T4/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [' Exec-managerial', ' Craft-repair', ' Craft-repair', ' Adm-clerical', ' Sales']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/model.pkl\n",
      "Evaluation: accuracy on test data: 0.3036275948836234\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.3036275948836234\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d1c050c-9fcd-4162-9676-c8df22b4a6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T1/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T2/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T3/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T4/model.pkl\n",
      "Loading: /Users/byeongsikbu/python/autogluon/AutogluonModels/ag-20230606_074956/models/LightGBM/T5/model.pkl\n",
      "Loading: AutogluonModels/ag-20230606_074956/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.328481       0.180445  3.388797                0.000683           0.339182            2       True          6\n",
      "1          LightGBM/T3   0.323765       0.014499  0.310731                0.014499           0.310731            1       True          3\n",
      "2          LightGBM/T5   0.310847       0.017980  0.526610                0.017980           0.526610            1       True          5\n",
      "3          LightGBM/T1   0.303260       0.037204  0.656409                0.037204           0.656409            1       True          1\n",
      "4          LightGBM/T2   0.289932       0.030602  0.858524                0.030602           0.858524            1       True          2\n",
      "5          LightGBM/T4   0.280910       0.079478  0.697340                0.079478           0.697340            1       True          4\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'LGBModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 2 | ['sex', 'class']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20230606_074956/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d882b5-98fb-4e15-abf5-ac4738693707",
   "metadata": {},
   "source": [
    "### Model ensembling with stacking/bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a610e-2f63-412c-bc10-7d1b9295542c",
   "metadata": {},
   "source": [
    "tuning_data   autogluon     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25359cee-3f8e-4065-bb0b-0b4bb6be821d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_075306/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_075306/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8513.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 2 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1656\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 2 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2781\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1411\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2781\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_075306/\")\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {'NN_TORCH': {'num_epochs': 2}, \n",
    "                       'GBM': {'num_boost_round': 20}}\n",
    "predictor = TabularPredictor(label=label, \n",
    "                             eval_metric=metric\n",
    "                            ).fit(train_data,\n",
    "                                  num_bag_folds=5, # 5~10\n",
    "                                  num_bag_sets=1, \n",
    "                                  num_stack_levels=1, # 1~3\n",
    "                                  hyperparameters = hyperparameters,  # last  argument is just for quick demo here, omit it in real applications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81c76abb-de8f-4197-b9c2-55b5eeef42f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"agModels-predictOccupation/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8446.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 2 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.93s of the 29.93s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 29.14s of the 29.14s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1656\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 28.87s of the 28.87s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3149\t = Validation score   (accuracy)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 28.17s of the 28.17s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1718\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 27.9s of the 27.9s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3292\t = Validation score   (accuracy)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 27.17s of the 27.17s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1677\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 26.9s of the 26.9s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3129\t = Validation score   (accuracy)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 26.21s of the 26.21s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1656\t = Validation score   (accuracy)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Repeating k-fold bagging: 5/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 25.94s of the 25.93s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3108\t = Validation score   (accuracy)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 25.23s of the 25.23s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1595\t = Validation score   (accuracy)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Repeating k-fold bagging: 6/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 24.96s of the 24.96s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3088\t = Validation score   (accuracy)\n",
      "\t4.11s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 24.27s of the 24.27s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Repeating k-fold bagging: 7/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 24.0s of the 24.0s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3088\t = Validation score   (accuracy)\n",
      "\t4.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 23.28s of the 23.28s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Repeating k-fold bagging: 8/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 23.0s of the 23.0s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t5.49s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 22.28s of the 22.28s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Repeating k-fold bagging: 9/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 22.0s of the 22.0s of remaining time.\n",
      "\tFitting 5 child models (S9F1 - S9F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3047\t = Validation score   (accuracy)\n",
      "\t6.15s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 21.3s of the 21.3s of remaining time.\n",
      "\tFitting 5 child models (S9F1 - S9F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Repeating k-fold bagging: 10/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 21.03s of the 21.03s of remaining time.\n",
      "\tFitting 5 child models (S10F1 - S10F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3006\t = Validation score   (accuracy)\n",
      "\t6.87s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 20.28s of the 20.28s of remaining time.\n",
      "\tFitting 5 child models (S10F1 - S10F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Repeating k-fold bagging: 11/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 19.99s of the 19.99s of remaining time.\n",
      "\tFitting 5 child models (S11F1 - S11F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2965\t = Validation score   (accuracy)\n",
      "\t7.6s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 19.23s of the 19.22s of remaining time.\n",
      "\tFitting 5 child models (S11F1 - S11F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t2.69s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Repeating k-fold bagging: 12/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 18.94s of the 18.94s of remaining time.\n",
      "\tFitting 5 child models (S12F1 - S12F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3006\t = Validation score   (accuracy)\n",
      "\t8.44s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 18.06s of the 18.06s of remaining time.\n",
      "\tFitting 5 child models (S12F1 - S12F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t2.94s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Repeating k-fold bagging: 13/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 17.78s of the 17.78s of remaining time.\n",
      "\tFitting 5 child models (S13F1 - S13F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2986\t = Validation score   (accuracy)\n",
      "\t9.16s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 17.02s of the 17.02s of remaining time.\n",
      "\tFitting 5 child models (S13F1 - S13F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t3.18s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Repeating k-fold bagging: 14/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 16.75s of the 16.74s of remaining time.\n",
      "\tFitting 5 child models (S14F1 - S14F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3006\t = Validation score   (accuracy)\n",
      "\t9.86s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 16.02s of the 16.02s of remaining time.\n",
      "\tFitting 5 child models (S14F1 - S14F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t3.43s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Repeating k-fold bagging: 15/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15.74s of the 15.74s of remaining time.\n",
      "\tFitting 5 child models (S15F1 - S15F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2965\t = Validation score   (accuracy)\n",
      "\t10.58s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 14.98s of the 14.98s of remaining time.\n",
      "\tFitting 5 child models (S15F1 - S15F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t3.67s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Repeating k-fold bagging: 16/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 14.71s of the 14.71s of remaining time.\n",
      "\tFitting 5 child models (S16F1 - S16F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2965\t = Validation score   (accuracy)\n",
      "\t11.25s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 14.01s of the 14.01s of remaining time.\n",
      "\tFitting 5 child models (S16F1 - S16F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t3.91s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Repeating k-fold bagging: 17/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 13.73s of the 13.73s of remaining time.\n",
      "\tFitting 5 child models (S17F1 - S17F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3006\t = Validation score   (accuracy)\n",
      "\t11.98s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 12.96s of the 12.96s of remaining time.\n",
      "\tFitting 5 child models (S17F1 - S17F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t4.16s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Repeating k-fold bagging: 18/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 12.68s of the 12.68s of remaining time.\n",
      "\tFitting 5 child models (S18F1 - S18F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2986\t = Validation score   (accuracy)\n",
      "\t12.73s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 11.9s of the 11.9s of remaining time.\n",
      "\tFitting 5 child models (S18F1 - S18F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t4.4s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Repeating k-fold bagging: 19/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 11.63s of the 11.63s of remaining time.\n",
      "\tFitting 5 child models (S19F1 - S19F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2924\t = Validation score   (accuracy)\n",
      "\t13.45s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 10.87s of the 10.87s of remaining time.\n",
      "\tFitting 5 child models (S19F1 - S19F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t4.63s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Repeating k-fold bagging: 20/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 10.6s of the 10.6s of remaining time.\n",
      "\tFitting 5 child models (S20F1 - S20F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2965\t = Validation score   (accuracy)\n",
      "\t14.13s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 9.89s of the 9.89s of remaining time.\n",
      "\tFitting 5 child models (S20F1 - S20F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1575\t = Validation score   (accuracy)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.93s of the 9.61s of remaining time.\n",
      "\t0.3231\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.45s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictOccupation/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictOccupation'  # folder where to store trained models\n",
    "hyperparameters = {'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}}\n",
    "\n",
    "predictor = TabularPredictor(label=label, \n",
    "                             eval_metric=metric, \n",
    "                             path=save_path).fit(\n",
    "    train_data, \n",
    "    auto_stack=True,\n",
    "    time_limit=30, \n",
    "    hyperparameters= hyperparameters # last 2 arguments are for quick demo, omit them in real applications\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485897ad-24be-44dc-bc6c-cb585c0d7e7a",
   "metadata": {},
   "source": [
    "### prediction options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa041765-a7cb-4bff-9822-87de42e5e09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fbcaceb-36c5-41e7-925d-13572c298d34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'class']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52b045fb-43b5-4c01-93b7-a2e8f1d0bba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age workclass  fnlwgt      education  education-num marital-status  \\\n",
      "5000   49   Private  259087   Some-college             10       Divorced   \n",
      "\n",
      "        relationship    race      sex  capital-gain  capital-loss  \\\n",
      "5000   Not-in-family   White   Female             0             0   \n",
      "\n",
      "      hours-per-week  native-country   class  \n",
      "5000              40   United-States   <=50K  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000     Exec-managerial\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "print(datapoint)\n",
    "predictor.predict(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12a82a5a-bda7-4dd8-a321-1a6b0944f579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>Adm-clerical</th>\n",
       "      <th>Armed-Forces</th>\n",
       "      <th>Craft-repair</th>\n",
       "      <th>Exec-managerial</th>\n",
       "      <th>Farming-fishing</th>\n",
       "      <th>Handlers-cleaners</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Other-service</th>\n",
       "      <th>Priv-house-serv</th>\n",
       "      <th>Prof-specialty</th>\n",
       "      <th>Protective-serv</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Tech-support</th>\n",
       "      <th>Transport-moving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.070368</td>\n",
       "      <td>0.107069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101387</td>\n",
       "      <td>0.140451</td>\n",
       "      <td>0.05347</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>0.075378</td>\n",
       "      <td>0.078306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096707</td>\n",
       "      <td>0.051346</td>\n",
       "      <td>0.074186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ?   Adm-clerical   Armed-Forces   Craft-repair   Exec-managerial  \\\n",
       "5000  0.070368       0.107069            0.0       0.101387          0.140451   \n",
       "\n",
       "       Farming-fishing   Handlers-cleaners   Machine-op-inspct  \\\n",
       "5000           0.05347            0.063921            0.075378   \n",
       "\n",
       "       Other-service   Priv-house-serv   Prof-specialty   Protective-serv  \\\n",
       "5000        0.078306               0.0         0.087411               0.0   \n",
       "\n",
       "         Sales   Tech-support   Transport-moving  \n",
       "5000  0.096707       0.051346           0.074186  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d3167ff-9e64-4744-98bb-c79cba512f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5151d666-3b09-419e-966d-5921366f1ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.283078</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>1.080664</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1.080664</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.270287</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>2.367221</td>\n",
       "      <td>0.597866</td>\n",
       "      <td>19.059679</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.157464</td>\n",
       "      <td>1.285475</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1.285475</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  score_val  pred_time_test  \\\n",
       "0        LightGBM_BAG_L1    0.283078   0.296524        1.080664   \n",
       "1    WeightedEnsemble_L2    0.270287   0.323108        2.367221   \n",
       "2  NeuralNetTorch_BAG_L1    0.129377   0.157464        1.285475   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.197598  14.128732                 1.080664                0.197598   \n",
       "1       0.597866  19.059679                 0.001082                0.000225   \n",
       "2       0.400043   4.877741                 1.285475                0.400043   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          14.128732            1       True          1  \n",
       "1           0.053206            2       True          3  \n",
       "2           4.877741            1       True          2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c420b899-22e9-4823-aa43-e80a1466e64c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "      <th>num_features</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>0.597866</td>\n",
       "      <td>19.059679</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[LightGBM_BAG_L1_1, LightGBM_BAG_L1_4, LightGBM_BAG_L1_8, LightGBM_BAG_L1_11, LightGBM_BAG_L1_6, NeuralNetTorch_BAG_L1_1, NeuralNetTorch_BAG_L1_7, LightGBM_BAG_L1_3, NeuralNetTorch_BAG_L1_3, NeuralNetTorch_BAG_L1_8, LightGBM_BAG_L1_10, NeuralNetTorch_BAG_L1_10, LightGBM_BAG_L1_2, LightGBM_BAG_L1_5, LightGBM_BAG_L1_7, NeuralNetTorch_BAG_L1_4, NeuralNetTorch_BAG_L1_2, NeuralNetTorch_BAG_L1_9, LightGBM_BAG_L1_0, NeuralNetTorch_BAG_L1_5, NeuralNetTorch_BAG_L1_6, LightGBM_BAG_L1_9, NeuralNetTorch_BAG_L1_0, NeuralNetTorch_BAG_L1_11]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 100}</td>\n",
       "      <td>{'ensemble_size': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[LightGBM_BAG_L1, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[age, class, sex, workclass, education, race, education-num, capital-gain, capital-loss, relationship, native-country, hours-per-week, fnlwgt, marital-status]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'num_boost_round': 20}</td>\n",
       "      <td>{'num_boost_round': 12}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.157464</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[age, class, sex, workclass, education, race, education-num, capital-gain, capital-loss, relationship, native-country, hours-per-week, fnlwgt, marital-status]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 2, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}</td>\n",
       "      <td>{'batch_size': 32, 'num_epochs': 2}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_val  pred_time_val   fit_time  \\\n",
       "0    WeightedEnsemble_L2   0.323108       0.597866  19.059679   \n",
       "1        LightGBM_BAG_L1   0.296524       0.197598  14.128732   \n",
       "2  NeuralNetTorch_BAG_L1   0.157464       0.400043   4.877741   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000225           0.053206            2       True   \n",
       "1                0.197598          14.128732            1       True   \n",
       "2                0.400043           4.877741            1       True   \n",
       "\n",
       "   fit_order  num_features  ...  \\\n",
       "0          3            24  ...   \n",
       "1          1            14  ...   \n",
       "2          2            14  ...   \n",
       "\n",
       "                                                                                              hyperparameters  \\\n",
       "0  {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "1   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "2   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "\n",
       "   hyperparameters_fit  \\\n",
       "0                   {}   \n",
       "1                   {}   \n",
       "2                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                           ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               features  \\\n",
       "0  [LightGBM_BAG_L1_1, LightGBM_BAG_L1_4, LightGBM_BAG_L1_8, LightGBM_BAG_L1_11, LightGBM_BAG_L1_6, NeuralNetTorch_BAG_L1_1, NeuralNetTorch_BAG_L1_7, LightGBM_BAG_L1_3, NeuralNetTorch_BAG_L1_3, NeuralNetTorch_BAG_L1_8, LightGBM_BAG_L1_10, NeuralNetTorch_BAG_L1_10, LightGBM_BAG_L1_2, LightGBM_BAG_L1_5, LightGBM_BAG_L1_7, NeuralNetTorch_BAG_L1_4, NeuralNetTorch_BAG_L1_2, NeuralNetTorch_BAG_L1_9, LightGBM_BAG_L1_0, NeuralNetTorch_BAG_L1_5, NeuralNetTorch_BAG_L1_6, LightGBM_BAG_L1_9, NeuralNetTorch_BAG_L1_0, NeuralNetTorch_BAG_L1_11]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                        [age, class, sex, workclass, education, race, education-num, capital-gain, capital-loss, relationship, native-country, hours-per-week, fnlwgt, marital-status]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                        [age, class, sex, workclass, education, race, education-num, capital-gain, capital-loss, relationship, native-country, hours-per-week, fnlwgt, marital-status]   \n",
       "\n",
       "   compile_time  \\\n",
       "0          None   \n",
       "1          None   \n",
       "2          None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           child_hyperparameters  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'ensemble_size': 100}   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {'learning_rate': 0.05, 'num_boost_round': 20}   \n",
       "2  {'num_epochs': 2, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}   \n",
       "\n",
       "             child_hyperparameters_fit  \\\n",
       "0                {'ensemble_size': 19}   \n",
       "1              {'num_boost_round': 12}   \n",
       "2  {'batch_size': 32, 'num_epochs': 2}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                             child_ag_args_fit  \\\n",
       "0                                          {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "\n",
       "                                  ancestors            descendants  \n",
       "0  [LightGBM_BAG_L1, NeuralNetTorch_BAG_L1]                     []  \n",
       "1                                        []  [WeightedEnsemble_L2]  \n",
       "2                                        []  [WeightedEnsemble_L2]  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(extra_info=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64d3a717-c31e-4f02-a16a-e0f52a0e30ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.283078</td>\n",
       "      <td>0.283078</td>\n",
       "      <td>0.177364</td>\n",
       "      <td>-11.749224</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>1.111216</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1.111216</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.270287</td>\n",
       "      <td>0.270287</td>\n",
       "      <td>0.167753</td>\n",
       "      <td>-11.728956</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>2.413881</td>\n",
       "      <td>0.597866</td>\n",
       "      <td>19.059679</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-11.760057</td>\n",
       "      <td>0.157464</td>\n",
       "      <td>1.301599</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1.301599</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  accuracy  balanced_accuracy   log_loss  \\\n",
       "0        LightGBM_BAG_L1    0.283078  0.283078           0.177364 -11.749224   \n",
       "1    WeightedEnsemble_L2    0.270287  0.270287           0.167753 -11.728956   \n",
       "2  NeuralNetTorch_BAG_L1    0.129377  0.129377           0.066667 -11.760057   \n",
       "\n",
       "   score_val  pred_time_test  pred_time_val   fit_time  \\\n",
       "0   0.296524        1.111216       0.197598  14.128732   \n",
       "1   0.323108        2.413881       0.597866  19.059679   \n",
       "2   0.157464        1.301599       0.400043   4.877741   \n",
       "\n",
       "   pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0                 1.111216                0.197598          14.128732   \n",
       "1                 0.001066                0.000225           0.053206   \n",
       "2                 1.301599                0.400043           4.877741   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            1       True          1  \n",
       "1            2       True          3  \n",
       "2            1       True          2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'], silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe4c12-f374-4d3d-afda-c20c06522800",
   "metadata": {},
   "source": [
    "### particular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33ebf860-a55e-449f-9482-c22012bbdfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LightGBM_BAG_L1', 'NeuralNetTorch_BAG_L1', 'WeightedEnsemble_L2']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "168d5318-c0d6-43e5-a015-dfd96804bcd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from LightGBM_BAG_L1 model:  Exec-managerial\n"
     ]
    }
   ],
   "source": [
    "i = 0  # index of model to use\n",
    "model_to_use = predictor.get_model_names()[i]\n",
    "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
    "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92d9d85d-b024-4952-9136-cc70a0f918d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.2702872719647725\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.2702872719647725,\n",
      "    \"balanced_accuracy\": 0.1677525538139834,\n",
      "    \"mcc\": 0.179705418939371\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01fc5921-5850-47bd-813f-b8fd4a6609c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.2702872719647725\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.2702872719647725,\n",
      "    \"balanced_accuracy\": 0.1677525538139834,\n",
      "    \"mcc\": 0.179705418939371\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d93ed-2e59-48d4-931e-fd6e31ba5bcd",
   "metadata": {},
   "source": [
    "### Interpretability (feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "485ea2a3-db63-4bc5-af32-32247b1a54ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 14 features using 4637 rows with 5 shuffle sets...\n",
      "\t182.83s\t= Expected runtime (36.57s per shuffle set)\n",
      "\t111.54s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.056071</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>2.007034e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.060224</td>\n",
       "      <td>0.051917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.036230</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>8.667111e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038406</td>\n",
       "      <td>0.034055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.030149</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>4.814644e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.027369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.027949</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>2.149158e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.034636</td>\n",
       "      <td>0.021262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>9.053658e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026986</td>\n",
       "      <td>0.006225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>8.087244e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>7.881967e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>-0.002352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>1.438016e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>-0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>2.391255e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>1.745985e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>3.170136e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>-0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>3.241306e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>-0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>-0.000474</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>9.514074e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>-0.000733</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>8.258416e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>-0.003914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev       p_value  n  p99_high   p99_low\n",
       "education-num     0.056071  0.002017  2.007034e-07  5  0.060224  0.051917\n",
       "workclass         0.036230  0.001056  8.667111e-08  5  0.038406  0.034055\n",
       "sex               0.030149  0.001350  4.814644e-07  5  0.032929  0.027369\n",
       "hours-per-week    0.027949  0.003248  2.149158e-05  5  0.034636  0.021262\n",
       "age               0.016606  0.005041  9.053658e-04  5  0.026986  0.006225\n",
       "class             0.006599  0.001945  8.087244e-04  5  0.010603  0.002595\n",
       "relationship      0.001423  0.001834  7.881967e-02  5  0.005199 -0.002352\n",
       "education         0.001337  0.000894  1.438016e-02  5  0.003179 -0.000504\n",
       "capital-loss      0.000733  0.000289  2.391255e-03  5  0.001329  0.000137\n",
       "native-country    0.000345  0.000246  1.745985e-02  5  0.000851 -0.000161\n",
       "race              0.000129  0.000562  3.170136e-01  5  0.001287 -0.001029\n",
       "marital-status    0.000086  0.000392  3.241306e-01  5  0.000893 -0.000720\n",
       "capital-gain     -0.000474  0.000492  9.514074e-01  5  0.000538 -0.001487\n",
       "fnlwgt           -0.000733  0.001545  8.258416e-01  5  0.002447 -0.003914"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83d6bd-f7a2-49cf-b4f5-c84076e14283",
   "metadata": {},
   "source": [
    "### Accelerating inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d0747-606b-4e46-ba2d-de8775ac93f0",
   "metadata": {},
   "source": [
    "- refit_full : -Quality, +FitTime\n",
    "- persist_models : ++ MemoryUsage\n",
    "- infer_limit : -Quality\n",
    "- distill : -Quality, ++FitTime\n",
    "- feature pruning : -Quality?, ++FitTime\n",
    "- use faster hardware : +Hardware\n",
    "- manual hyperparameters adjustmetn : -Quality, ++UserMLExpertise\n",
    "- manual data processing : +++UserMLExpertise, +++UserCode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713c8b7-1936-40a0-83db-92996b0d8184",
   "metadata": {},
   "source": [
    "### Kepping models in memoery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00cee2f1-a9c5-46a6-b6af-3ed8891bd2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting 3 models in memory. Models will require 0.62% of memory.\n",
      "Evaluation: accuracy on test data: 0.25\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.25,\n",
      "    \"balanced_accuracy\": 0.3208333333333336,\n",
      "    \"mcc\": 0.13582634199860824\n",
      "}\n",
      "Unpersisted 3 models: ['WeightedEnsemble_L2', 'LightGBM_BAG_L1', 'NeuralNetTorch_BAG_L1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [' Exec-managerial' ' Exec-managerial' ' Craft-repair' ' Adm-clerical'\n",
      " ' ?' ' Exec-managerial' ' Exec-managerial' ' Sales' ' Exec-managerial'\n",
      " ' Adm-clerical' ' Other-service' ' Exec-managerial' ' Exec-managerial'\n",
      " ' Exec-managerial' ' Adm-clerical' ' ?' ' Craft-repair' ' Craft-repair'\n",
      " ' Exec-managerial' ' Craft-repair']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WeightedEnsemble_L2', 'LightGBM_BAG_L1', 'NeuralNetTorch_BAG_L1']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.persist_models()\n",
    "\n",
    "num_test = 20\n",
    "preds = np.array(['']*num_test, dtype='object')\n",
    "for i in range(num_test):\n",
    "    datapoint = test_data_nolabel.iloc[[i]]\n",
    "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
    "    preds[i] = pred_numpy[0]\n",
    "\n",
    "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
    "print(\"Predictions: \", preds)\n",
    "\n",
    "predictor.unpersist_models()  # free memory by clearing models, future predict() calls will load models from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70eebcc-661a-4835-8145-d25dd35221a8",
   "metadata": {},
   "source": [
    "### Inference speed as a fit constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3067f495-1541-456f-a2db-26c6d8c14885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_080905/\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_080905/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8156.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\t1.134s\t= Feature Preprocessing Time (1 row | 10000 batch size)\n",
      "\t\tFeature Preprocessing requires 2.27% of the overall inference constraint (0.05ms)\n",
      "\t\t0.049ms inference time budget remaining for models...\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 391, Val Rows: 98\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 29.82s of the 29.82s of remaining time.\n",
      "\t0.1633\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t0.653s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t0.653s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: KNeighborsDist ... Training model for up to 29.75s of the 29.75s of remaining time.\n",
      "\t0.1224\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t0.707s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t0.707s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 29.67s of the 29.67s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t5.073s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t5.073s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: LightGBMXT ... Training model for up to 29.36s of the 29.36s of remaining time.\n",
      "\t0.3571\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t5.382s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t5.382s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: LightGBM ... Training model for up to 28.62s of the 28.62s of remaining time.\n",
      "\t0.3673\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t3.359s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t3.359s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: RandomForestGini ... Training model for up to 27.38s of the 27.38s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "\t9.3s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t9.3s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: RandomForestEntr ... Training model for up to 26.93s of the 26.93s of remaining time.\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "\t8.298s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t8.298s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: CatBoost ... Training model for up to 26.49s of the 26.49s of remaining time.\n",
      "\t0.3469\t = Validation score   (accuracy)\n",
      "\t9.91s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t2.405s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t2.405s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 16.57s of the 16.57s of remaining time.\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "\t8.788s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t8.788s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 16.18s of the 16.18s of remaining time.\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "\t8.655s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t8.655s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: XGBoost ... Training model for up to 15.78s of the 15.78s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t1.887s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t1.887s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 14.89s of the 14.89s of remaining time.\n",
      "\t0.3163\t = Validation score   (accuracy)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t2.326s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t2.326s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Fitting model: LightGBMLarge ... Training model for up to 13.99s of the 13.99s of remaining time.\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t3.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t1.701s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t1.701s\t = Validation runtime (1 row | 10000 batch size)\n",
      "Removing 5/13 base models to satisfy inference constraint (constraint=0.046ms) ...\n",
      "\t0.059ms\t-> 0.058ms\t(KNeighborsDist)\n",
      "\t0.058ms\t-> 0.057ms\t(KNeighborsUnif)\n",
      "\t0.057ms\t-> 0.048ms\t(ExtraTreesGini)\n",
      "\t0.048ms\t-> 0.047ms\t(LightGBMLarge)\n",
      "\t0.047ms\t-> 0.038ms\t(RandomForestEntr)\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.82s of the 10.66s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t0.067s\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
      "\t1.954s\t = Validation runtime (1 row | 10000 batch size)\n",
      "AutoGluon training complete, total runtime = 19.46s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_080905/\")\n",
      "Persisting 2 models in memory. Models will require 0.06% of memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.863583</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.863583</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.111595</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>1.225938</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>1.225938</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.723984</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.723984</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>9.914283</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>9.914283</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.895814</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.895814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.302249</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.302249</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.354717</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.354717</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>0.346944</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>0.346944</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>0.325546</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>0.325546</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>3.304460</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>3.304460</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.019987</td>\n",
       "      <td>0.327211</td>\n",
       "      <td>0.019987</td>\n",
       "      <td>0.327211</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.068890</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.068890</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.074305</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.074305</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val  fit_time  \\\n",
       "0               XGBoost   0.397959       0.001756  0.863583   \n",
       "1   WeightedEnsemble_L2   0.397959       0.002033  0.975178   \n",
       "2              LightGBM   0.367347       0.003443  1.225938   \n",
       "3            LightGBMXT   0.357143       0.002538  0.723984   \n",
       "4              CatBoost   0.346939       0.002195  9.914283   \n",
       "5        NeuralNetTorch   0.316327       0.003835  0.895814   \n",
       "6       NeuralNetFastAI   0.306122       0.003783  0.302249   \n",
       "7      RandomForestGini   0.306122       0.024727  0.354717   \n",
       "8      RandomForestEntr   0.295918       0.019253  0.346944   \n",
       "9        ExtraTreesEntr   0.295918       0.019821  0.325546   \n",
       "10        LightGBMLarge   0.265306       0.002362  3.304460   \n",
       "11       ExtraTreesGini   0.265306       0.019987  0.327211   \n",
       "12       KNeighborsUnif   0.163265       0.002261  0.068890   \n",
       "13       KNeighborsDist   0.122449       0.002014  0.074305   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001756           0.863583            1       True   \n",
       "1                 0.000277           0.111595            2       True   \n",
       "2                 0.003443           1.225938            1       True   \n",
       "3                 0.002538           0.723984            1       True   \n",
       "4                 0.002195           9.914283            1       True   \n",
       "5                 0.003835           0.895814            1       True   \n",
       "6                 0.003783           0.302249            1       True   \n",
       "7                 0.024727           0.354717            1       True   \n",
       "8                 0.019253           0.346944            1       True   \n",
       "9                 0.019821           0.325546            1       True   \n",
       "10                0.002362           3.304460            1       True   \n",
       "11                0.019987           0.327211            1       True   \n",
       "12                0.002261           0.068890            1       True   \n",
       "13                0.002014           0.074305            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1          14  \n",
       "2           5  \n",
       "3           4  \n",
       "4           8  \n",
       "5          12  \n",
       "6           3  \n",
       "7           6  \n",
       "8           7  \n",
       "9          10  \n",
       "10         13  \n",
       "11          9  \n",
       "12          1  \n",
       "13          2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At most 0.05 ms per row (20000 rows per second throughput)\n",
    "infer_limit = 0.00005 # 1   \n",
    "# adhere to infer_limit with batches of size 10000 (batch-inference, easier to satisfy infer_limit)\n",
    "infer_limit_batch_size = 10000 #    \n",
    "# adhere to infer_limit with batches of size 1 (online-inference, much harder to satisfy infer_limit)\n",
    "# infer_limit_batch_size = 1  # Note that infer_limit<0.02 when infer_limit_batch_size=1 can be difficult to satisfy.\n",
    "predictor_infer_limit = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=30,\n",
    "    infer_limit=infer_limit,\n",
    "    infer_limit_batch_size=infer_limit_batch_size,\n",
    ")\n",
    "\n",
    "# NOTE: If bagging was enabled, it is important to call refit_full at this stage.\n",
    "#  infer_limit assumes that the user will call refit_full after fit.\n",
    "# predictor_infer_limit.refit_full()\n",
    "\n",
    "# NOTE: To align with inference speed calculated during fit, models must be persisted.\n",
    "predictor_infer_limit.persist_models()\n",
    "# Below is an optimized version that only persists the minimum required models for prediction.\n",
    "# predictor_infer_limit.persist_models('best')\n",
    "\n",
    "predictor_infer_limit.leaderboard(silent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f0a296f-9427-4c9f-bea2-704e28fa4834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is able to predict 220287.9 rows per second. (User-specified Throughput = 20000.0)\n",
      "Model uses 9.1% of infer_limit time per row.\n",
      "Model satisfies inference constraint: True\n"
     ]
    }
   ],
   "source": [
    "test_data_batch = test_data.sample(infer_limit_batch_size, replace=True, ignore_index=True)\n",
    "\n",
    "import time\n",
    "time_start = time.time()\n",
    "predictor_infer_limit.predict(test_data_batch)\n",
    "time_end = time.time()\n",
    "\n",
    "infer_time_per_row = (time_end - time_start) / len(test_data_batch)\n",
    "rows_per_second = 1 / infer_time_per_row\n",
    "infer_time_per_row_ratio = infer_time_per_row / infer_limit\n",
    "is_constraint_satisfied = infer_time_per_row_ratio <= 1\n",
    "\n",
    "print(f'Model is able to predict {round(rows_per_second, 1)} rows per second. (User-specified Throughput = {1 / infer_limit})')\n",
    "print(f'Model uses {round(infer_time_per_row_ratio * 100, 1)}% of infer_limit time per row.')\n",
    "print(f'Model satisfies inference constraint: {is_constraint_satisfied}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911da7b-242d-4a0b-989b-03f0fb6ca844",
   "metadata": {},
   "source": [
    "### Using smaller ensemble or faster model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15aa8744-b49a-4048-92c3-ac5113a03e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2Best ...\n",
      "\t0.3231\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative ensembles you can use for prediction: ['WeightedEnsemble_L2Best']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2Best</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>0.597859</td>\n",
       "      <td>19.080851</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.074378</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val  pred_time_val   fit_time  \\\n",
       "0  WeightedEnsemble_L2Best   0.323108       0.597859  19.080851   \n",
       "1          LightGBM_BAG_L1   0.296524       0.197598  14.128732   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000218           0.074378            2       True   \n",
       "1                0.197598          14.128732            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          4  \n",
       "1          1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\n",
    "print(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n",
    "\n",
    "predictor.leaderboard(only_pareto_frontier=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4222afc-88f6-4413-9592-7b63cd266f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting model WeightedEnsemble_L2Best. All files under agModels-predictOccupation/models/WeightedEnsemble_L2Best/ will be removed.\n"
     ]
    }
   ],
   "source": [
    "model_for_prediction = additional_ensembles[0]\n",
    "predictions = predictor.predict(test_data, model=model_for_prediction)\n",
    "predictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)  # delete these extra models so they don't affect rest of tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4df69-bf4a-451d-9bc6-54751d1c8d87",
   "metadata": {},
   "source": [
    "### Collapsing bagged ensembles via rifit_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38c8565d-841a-4cd0-8db1-7327b954e448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t0.06s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 0.41s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of each refit-full model corresponding to a previous bagged ensemble:\n",
      "{'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL', 'NeuralNetTorch_BAG_L1': 'NeuralNetTorch_BAG_L1_FULL', 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.283078</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>1.085370</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1.085370</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.270287</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>2.440959</td>\n",
       "      <td>0.597866</td>\n",
       "      <td>19.059679</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>0.269868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124398</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124398</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>0.257077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242409</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.157464</td>\n",
       "      <td>1.354448</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1.354448</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_test  score_val  pred_time_test  \\\n",
       "0             LightGBM_BAG_L1    0.283078   0.296524        1.085370   \n",
       "1         WeightedEnsemble_L2    0.270287   0.323108        2.440959   \n",
       "2        LightGBM_BAG_L1_FULL    0.269868        NaN        0.012544   \n",
       "3    WeightedEnsemble_L2_FULL    0.257077        NaN        0.033614   \n",
       "4  NeuralNetTorch_BAG_L1_FULL    0.129377        NaN        0.019881   \n",
       "5       NeuralNetTorch_BAG_L1    0.129377   0.157464        1.354448   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.197598  14.128732                 1.085370                0.197598   \n",
       "1       0.597866  19.059679                 0.001141                0.000225   \n",
       "2            NaN   0.124398                 0.012544                     NaN   \n",
       "3            NaN   0.242409                 0.001189                     NaN   \n",
       "4            NaN   0.064805                 0.019881                     NaN   \n",
       "5       0.400043   4.877741                 1.354448                0.400043   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          14.128732            1       True          1  \n",
       "1           0.053206            2       True          3  \n",
       "2           0.124398            1       True          4  \n",
       "3           0.053206            2       True          6  \n",
       "4           0.064805            1       True          5  \n",
       "5           4.877741            1       True          2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refit_model_map = predictor.refit_full()\n",
    "print(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\n",
    "print(refit_model_map)\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf7907-cb48-4d6a-bef0-2d8132bde9b3",
   "metadata": {},
   "source": [
    "### Model distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a6883-a79c-4b59-b476-7e0393888ddf",
   "metadata": {},
   "source": [
    "The idea is to train the individual model (which we can call the student) to mimic the predictions of the full stack ensemble (the teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bce677f-1363-400f-8ede-d7b859227a10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling with teacher='WeightedEnsemble_L2_FULL', teacher_preds=soft, augment_method=spunge ...\n",
      "SPUNGE: Augmenting training data with 1955 synthetic samples for distillation...\n",
      "Distilling with each of these student models: ['LightGBM_DSTL', 'NeuralNetMXNet_DSTL', 'RandomForestMSE_DSTL', 'CatBoost_DSTL', 'NeuralNetTorch_DSTL']\n",
      "Fitting 5 L1 models ...\n",
      "Fitting model: LightGBM_DSTL ... Training model for up to 30.0s of the 30.0s of remaining time.\n",
      "\tNote: model has different eval_metric than default.\n",
      "\t-2.0909\t = Validation score   (-soft_log_loss)\n",
      "\t3.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_DSTL ... Training model for up to 26.28s of the 26.28s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetMXNet_DSTL to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: RandomForestMSE_DSTL ... Training model for up to 26.28s of the 26.28s of remaining time.\n",
      "\tNote: model has different eval_metric than default.\n",
      "\t-2.1191\t = Validation score   (-soft_log_loss)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_DSTL ... Training model for up to 25.56s of the 25.56s of remaining time.\n",
      "/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/catboost/core.py:2266: UserWarning: Can't optimze method \"evaluate\" because self argument is used\n",
      "  _check_train_params(params)\n",
      "\tRan out of time, early stopping on iteration 158.\n",
      "\tNote: model has different eval_metric than default.\n",
      "\t-2.1677\t = Validation score   (-soft_log_loss)\n",
      "\t25.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_DSTL ... Training model for up to 0.17s of the 0.17s of remaining time.\n",
      "/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "\tNot enough time to train first epoch. (Time Required: 0.12s, Time Left: 0.1s)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_DSTL.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Distilling with each of these student models: ['WeightedEnsemble_L2_DSTL']\n",
      "Fitting model: WeightedEnsemble_L2_DSTL ... Training model for up to 30.0s of the 0.08s of remaining time.\n",
      "\tNote: model has different eval_metric than default.\n",
      "\t-2.0885\t = Validation score   (-soft_log_loss)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Distilled model leaderboard:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2_DSTL   0.346939       0.026412   4.237754                0.000181           0.024037            2       True         10\n",
      "1             LightGBM_DSTL   0.306122       0.005275   3.652510                0.005275           3.652510            1       True          7\n",
      "2      RandomForestMSE_DSTL   0.306122       0.020956   0.561207                0.020956           0.561207            1       True          8\n",
      "3             CatBoost_DSTL   0.295918       0.002559  25.390957                0.002559          25.390957            1       True          9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LightGBM_DSTL', 'RandomForestMSE_DSTL', 'CatBoost_DSTL', 'WeightedEnsemble_L2_DSTL']\n",
      "predictions from LightGBM_DSTL: [' Exec-managerial', ' Exec-managerial', ' Craft-repair', ' Sales', ' Exec-managerial']\n",
      "                        model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0               LightGBM_DSTL    0.291256   0.306122        0.126910       0.005275   3.652510                 0.126910                0.005275           3.652510            1       True          7\n",
      "1    WeightedEnsemble_L2_DSTL    0.289788   0.346939        0.223685       0.026412   4.237754                 0.001342                0.000181           0.024037            2       True         10\n",
      "2               CatBoost_DSTL    0.287901   0.295918        0.035285       0.002559  25.390957                 0.035285                0.002559          25.390957            1       True          9\n",
      "3        RandomForestMSE_DSTL    0.284546   0.306122        0.095433       0.020956   0.561207                 0.095433                0.020956           0.561207            1       True          8\n",
      "4             LightGBM_BAG_L1    0.283078   0.296524        1.237438       0.197598  14.128732                 1.237438                0.197598          14.128732            1       True          1\n",
      "5         WeightedEnsemble_L2    0.270287   0.323108        3.146374       0.597866  19.059679                 0.001375                0.000225           0.053206            2       True          3\n",
      "6        LightGBM_BAG_L1_FULL    0.269868        NaN        0.013364            NaN   0.124398                 0.013364                     NaN           0.124398            1       True          4\n",
      "7    WeightedEnsemble_L2_FULL    0.257077        NaN        0.033950            NaN   0.242409                 0.001361                     NaN           0.053206            2       True          6\n",
      "8  NeuralNetTorch_BAG_L1_FULL    0.129377        NaN        0.019225            NaN   0.064805                 0.019225                     NaN           0.064805            1       True          5\n",
      "9       NeuralNetTorch_BAG_L1    0.129377   0.157464        1.907561       0.400043   4.877741                 1.907561                0.400043           4.877741            1       True          2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_DSTL</td>\n",
       "      <td>0.291256</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.126910</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>3.652510</td>\n",
       "      <td>0.126910</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>3.652510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2_DSTL</td>\n",
       "      <td>0.289788</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.223685</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>4.237754</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.024037</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_DSTL</td>\n",
       "      <td>0.287901</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>25.390957</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>25.390957</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE_DSTL</td>\n",
       "      <td>0.284546</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.095433</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>0.095433</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.283078</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>1.237438</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1.237438</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>14.128732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.270287</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>3.146374</td>\n",
       "      <td>0.597866</td>\n",
       "      <td>19.059679</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>0.269868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124398</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124398</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>0.257077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242409</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.129377</td>\n",
       "      <td>0.157464</td>\n",
       "      <td>1.907561</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1.907561</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>4.877741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_test  score_val  pred_time_test  \\\n",
       "0               LightGBM_DSTL    0.291256   0.306122        0.126910   \n",
       "1    WeightedEnsemble_L2_DSTL    0.289788   0.346939        0.223685   \n",
       "2               CatBoost_DSTL    0.287901   0.295918        0.035285   \n",
       "3        RandomForestMSE_DSTL    0.284546   0.306122        0.095433   \n",
       "4             LightGBM_BAG_L1    0.283078   0.296524        1.237438   \n",
       "5         WeightedEnsemble_L2    0.270287   0.323108        3.146374   \n",
       "6        LightGBM_BAG_L1_FULL    0.269868        NaN        0.013364   \n",
       "7    WeightedEnsemble_L2_FULL    0.257077        NaN        0.033950   \n",
       "8  NeuralNetTorch_BAG_L1_FULL    0.129377        NaN        0.019225   \n",
       "9       NeuralNetTorch_BAG_L1    0.129377   0.157464        1.907561   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.005275   3.652510                 0.126910                0.005275   \n",
       "1       0.026412   4.237754                 0.001342                0.000181   \n",
       "2       0.002559  25.390957                 0.035285                0.002559   \n",
       "3       0.020956   0.561207                 0.095433                0.020956   \n",
       "4       0.197598  14.128732                 1.237438                0.197598   \n",
       "5       0.597866  19.059679                 0.001375                0.000225   \n",
       "6            NaN   0.124398                 0.013364                     NaN   \n",
       "7            NaN   0.242409                 0.001361                     NaN   \n",
       "8            NaN   0.064805                 0.019225                     NaN   \n",
       "9       0.400043   4.877741                 1.907561                0.400043   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           3.652510            1       True          7  \n",
       "1           0.024037            2       True         10  \n",
       "2          25.390957            1       True          9  \n",
       "3           0.561207            1       True          8  \n",
       "4          14.128732            1       True          1  \n",
       "5           0.053206            2       True          3  \n",
       "6           0.124398            1       True          4  \n",
       "7           0.053206            2       True          6  \n",
       "8           0.064805            1       True          5  \n",
       "9           4.877741            1       True          2  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_models = predictor.distill(time_limit=30)  # specify much longer time limit in real applications\n",
    "print(student_models)\n",
    "preds_student = predictor.predict(test_data_nolabel, model=student_models[0])\n",
    "print(f\"predictions from {student_models[0]}:\", list(preds_student)[:5])\n",
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81109ee3-ed34-49b9-a6b8-c89cc75844b2",
   "metadata": {},
   "source": [
    "### Faster presets or hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8973c12a-ecc7-4775-9463-f0de401010b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_084537/\"\n",
      "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_084537/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7381.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 29.93s of the 29.93s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "\t0.3088\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 28.52s of the 28.52s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3497\t = Validation score   (accuracy)\n",
      "\t4.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 24.37s of the 24.37s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3395\t = Validation score   (accuracy)\n",
      "\t5.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 18.45s of the 18.45s of remaining time.\n",
      "\t0.3231\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 18.12s of the 18.12s of remaining time.\n",
      "\t0.2802\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 17.8s of the 17.8s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 173.\n",
      "\tRan out of time, early stopping on iteration 179.\n",
      "\tRan out of time, early stopping on iteration 198.\n",
      "\tRan out of time, early stopping on iteration 212.\n",
      "\tRan out of time, early stopping on iteration 252.\n",
      "\t0.3374\t = Validation score   (accuracy)\n",
      "\t16.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1.07s of the 1.07s of remaining time.\n",
      "\t0.3006\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 0.76s of the 0.76s of remaining time.\n",
      "\t0.3149\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.43s of the 0.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3395\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 0.0s of the 0.0s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.93s of the -0.03s of remaining time.\n",
      "\t0.3497\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.45s\t = Training   runtime\n",
      "Refit complete, total runtime = 0.51s\n",
      "Deleting model NeuralNetFastAI_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/NeuralNetFastAI_BAG_L1/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model RandomForestGini_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/RandomForestGini_BAG_L1/ will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/RandomForestEntr_BAG_L1/ will be removed.\n",
      "Deleting model CatBoost_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/CatBoost_BAG_L1/ will be removed.\n",
      "Deleting model ExtraTreesGini_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/ExtraTreesGini_BAG_L1/ will be removed.\n",
      "Deleting model ExtraTreesEntr_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/ExtraTreesEntr_BAG_L1/ will be removed.\n",
      "Deleting model XGBoost_BAG_L1. All files under AutogluonModels/ag-20230606_084537/models/XGBoost_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under AutogluonModels/ag-20230606_084537/models/WeightedEnsemble_L2/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_084537/\")\n"
     ]
    }
   ],
   "source": [
    "presets = ['good_quality', 'optimize_for_deployment']\n",
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580123d-427e-4b5c-9636-3d86f6d6df16",
   "metadata": {},
   "source": [
    "another options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5306cb3-37ed-4d85-b4b3-06be96747ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_084659/\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_084659/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7392.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 391, Val Rows: 98\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 29.95s of the 29.95s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 29.63s of the 29.63s of remaining time.\n",
      "\t0.3571\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 28.84s of the 28.84s of remaining time.\n",
      "\t0.3673\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 27.45s of the 27.45s of remaining time.\n",
      "\t0.3469\t = Validation score   (accuracy)\n",
      "\t9.93s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 17.52s of the 17.52s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 16.73s of the 16.73s of remaining time.\n",
      "\t0.3163\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 15.87s of the 15.87s of remaining time.\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t3.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.95s of the 12.11s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.99s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_084659/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78871aa1-1de7-4b7d-b4e7-72d9dfd670d3",
   "metadata": {},
   "source": [
    "another options 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "136c0b73-b203-457e-ad63-0a99616dec83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_084724/\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_084724/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7393.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 391, Val Rows: 98\n",
      "Excluded Model Types: ['KNN', 'NN_TORCH', 'custom']\n",
      "\tFound 'NN_TORCH' model in hyperparameters, but 'NN_TORCH' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 10 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 29.94s of the 29.94s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 29.63s of the 29.63s of remaining time.\n",
      "\t0.3571\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 28.86s of the 28.86s of remaining time.\n",
      "\t0.3673\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 27.71s of the 27.71s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 27.39s of the 27.38s of remaining time.\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 27.07s of the 27.07s of remaining time.\n",
      "\t0.3469\t = Validation score   (accuracy)\n",
      "\t10.9s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 16.16s of the 16.16s of remaining time.\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 15.85s of the 15.85s of remaining time.\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 15.55s of the 15.55s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 14.7s of the 14.7s of remaining time.\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t3.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.94s of the 11.0s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.15s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_084724/\")\n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['KNN', 'NN_TORCH', 'custom']\n",
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27463023-daf4-49ee-bd9c-30c1a4bef539",
   "metadata": {},
   "source": [
    "### (Advanced) Cache preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aafa63b1-b31b-4b3c-87a9-d1367920a719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#   test_data     \n",
    "test_data_preprocessed = predictor.transform_features(test_data)\n",
    "\n",
    "# The following call will be faster than a normal predict call because we are skipping the preprocessing stage.\n",
    "predictions = predictor.predict(test_data_preprocessed, transform_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bdf436-bc10-4421-a5b8-9e3953fcdcc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature Engineering \n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/tabular-feature-engineering.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af442e7-9a09-40b0-9c13-76a922a0c26d",
   "metadata": {},
   "source": [
    "\n",
    "- column types\n",
    "- column type detection\n",
    "- problem type detection\n",
    "- automatic feature engineering\n",
    "- numerical/categorical/datetime/text\n",
    "- additional processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90136bb2-4c49-4f92-9293-86210dfa4b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545774</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>y</td>\n",
       "      <td>d ghi ghi jkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.468674</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>x</td>\n",
       "      <td>ef ghi abc ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.767960</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>v</td>\n",
       "      <td>ef d ghi abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118771</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>y</td>\n",
       "      <td>jkl d abc ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630196</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>w</td>\n",
       "      <td>ghi ghi abc jkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.182318</td>\n",
       "      <td>-1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>v</td>\n",
       "      <td>ghi ef ef ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.562761</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>v</td>\n",
       "      <td>ghi abc ef jkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.797270</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>w</td>\n",
       "      <td>ef jkl ghi abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.502741</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>y</td>\n",
       "      <td>jkl jkl jkl ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.056356</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-30</td>\n",
       "      <td>w</td>\n",
       "      <td>abc ghi ghi abc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A  B          C  D                E\n",
       "0  -0.545774  0 2000-01-01  y    d ghi ghi jkl\n",
       "1  -0.468674  0 2000-01-02  x   ef ghi abc ghi\n",
       "2   1.767960  0 1999-12-31  v     ef d ghi abc\n",
       "3  -0.118771  1 2000-01-01  y     jkl d abc ef\n",
       "4   0.630196  0 1999-12-31  w  ghi ghi abc jkl\n",
       "..       ... ..        ... ..              ...\n",
       "95 -1.182318 -1 2000-01-01  v    ghi ef ef ghi\n",
       "96  0.562761  0 2000-01-01  v   ghi abc ef jkl\n",
       "97 -0.797270  0 2000-01-01  w   ef jkl ghi abc\n",
       "98  0.502741  0 1999-12-31  y   jkl jkl jkl ef\n",
       "99  2.056356  0 1999-12-30  w  abc ghi ghi abc\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import make_regression\n",
    "from datetime import datetime\n",
    "\n",
    "x, y = make_regression(n_samples = 100,n_features = 5,n_targets = 1, random_state = 1)\n",
    "dfx = pd.DataFrame(x, columns=['A','B','C','D','E'])\n",
    "dfy = pd.DataFrame(y, columns=['label'])\n",
    "\n",
    "# Create an integer column, a datetime column, a categorical column and a string column to demonstrate how they are processed.\n",
    "dfx['B'] = (dfx['B']).astype(int)\n",
    "dfx['C'] = datetime(2000,1,1) + pd.to_timedelta(dfx['C'].astype(int), unit='D')\n",
    "dfx['D'] = pd.cut(dfx['D'] * 10, [-np.inf,-5,0,5,np.inf],labels=['v','w','x','y'])\n",
    "dfx['E'] = pd.Series(list(' '.join(random.choice([\"abc\", \"d\", \"ef\", \"ghi\", \"jkl\"]) for i in range(4)) for j in range(100)))\n",
    "dataset=TabularDataset(dfx)\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70eff28b-bfe5-478f-b463-06aea80db74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.729289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.928562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-64.122910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.896493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-63.009453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-82.611204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.499687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.046040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>75.697053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>11.494156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label\n",
       "0   10.729289\n",
       "1   94.928562\n",
       "2  -64.122910\n",
       "3   38.896493\n",
       "4  -63.009453\n",
       "..        ...\n",
       "95 -82.611204\n",
       "96   8.499687\n",
       "97   6.046040\n",
       "98  75.697053\n",
       "99  11.494156\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502ddfb-7562-4e70-a1a7-36f118153330",
   "metadata": {},
   "source": [
    "### AutoMLPipelineFeatureGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c349b6e5-0bce-41aa-bd91-1c78e1a83b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7440.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['E']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 4 to 2 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])     : 1 | ['D']\n",
      "\t\t('datetime', [])     : 1 | ['C']\n",
      "\t\t('float', [])        : 1 | ['A']\n",
      "\t\t('int', [])          : 1 | ['B']\n",
      "\t\t('object', ['text']) : 1 | ['E']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 1 | ['D']\n",
      "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
      "\t\t('float', [])                       : 1 | ['A']\n",
      "\t\t('int', [])                         : 1 | ['B']\n",
      "\t\t('int', ['binned', 'text_special']) : 2 | ['E.char_count', 'E.symbol_ratio. ']\n",
      "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 3 | ['__nlp__.abc', '__nlp__.ghi', '__nlp__._total_']\n",
      "\t0.1s = Fit runtime\n",
      "\t5 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>C</th>\n",
       "      <th>C.year</th>\n",
       "      <th>C.month</th>\n",
       "      <th>C.day</th>\n",
       "      <th>C.dayofweek</th>\n",
       "      <th>E.char_count</th>\n",
       "      <th>E.symbol_ratio.</th>\n",
       "      <th>__nlp__.abc</th>\n",
       "      <th>__nlp__.ghi</th>\n",
       "      <th>__nlp__._total_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545774</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.468674</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946771200000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.767960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118771</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630196</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.182318</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.562761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.797270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.502741</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.056356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946512000000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A  B  D    E                   C  C.year  C.month  C.day  \\\n",
       "0  -0.545774  0  3  NaN  946684800000000000    2000        1      1   \n",
       "1  -0.468674  0  2  NaN  946771200000000000    2000        1      2   \n",
       "2   1.767960  0  0  NaN  946598400000000000    1999       12     31   \n",
       "3  -0.118771  1  3    5  946684800000000000    2000        1      1   \n",
       "4   0.630196  0  1  NaN  946598400000000000    1999       12     31   \n",
       "..       ... .. ..  ...                 ...     ...      ...    ...   \n",
       "95 -1.182318 -1  0  NaN  946684800000000000    2000        1      1   \n",
       "96  0.562761  0  0  NaN  946684800000000000    2000        1      1   \n",
       "97 -0.797270  0  1  NaN  946684800000000000    2000        1      1   \n",
       "98  0.502741  0  3  NaN  946598400000000000    1999       12     31   \n",
       "99  2.056356  0  1  NaN  946512000000000000    1999       12     30   \n",
       "\n",
       "    C.dayofweek  E.char_count  E.symbol_ratio.   __nlp__.abc  __nlp__.ghi  \\\n",
       "0             5             4                 2            0            2   \n",
       "1             6             5                 1            1            2   \n",
       "2             4             3                 3            1            1   \n",
       "3             5             3                 3            1            0   \n",
       "4             4             6                 0            1            2   \n",
       "..          ...           ...               ...          ...          ...   \n",
       "95            5             4                 2            0            2   \n",
       "96            5             5                 1            1            1   \n",
       "97            5             5                 1            1            1   \n",
       "98            4             5                 1            0            0   \n",
       "99            3             6                 0            2            2   \n",
       "\n",
       "    __nlp__._total_  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 2  \n",
       "..              ...  \n",
       "95                1  \n",
       "96                2  \n",
       "97                2  \n",
       "98                0  \n",
       "99                2  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
    "auto_ml_pipeline_feature_generator.fit_transform(X=dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "387b7cef-69ff-4ef0-a753-d91dbd9f3268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_085609/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_085609/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    100\n",
      "Train Data Columns: 5\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (186.98105511749836, -267.99365510467214, 9.38193, 71.29287)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "AutoMLPipelineFeatureGenerator is already fit, so the training data will be processed via .transform() instead of .fit_transform().\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])     : 1 | ['D']\n",
      "\t\t('datetime', [])     : 1 | ['C']\n",
      "\t\t('float', [])        : 1 | ['A']\n",
      "\t\t('int', [])          : 1 | ['B']\n",
      "\t\t('object', ['text']) : 1 | ['E']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 1 | ['D']\n",
      "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
      "\t\t('float', [])                       : 1 | ['A']\n",
      "\t\t('int', [])                         : 1 | ['B']\n",
      "\t\t('int', ['binned', 'text_special']) : 2 | ['E.char_count', 'E.symbol_ratio. ']\n",
      "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 3 | ['__nlp__.abc', '__nlp__.ghi', '__nlp__._total_']\n",
      "Data preprocessing and feature engineering runtime = 0.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 20\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t-56.3249\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-56.3249\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_085609/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x32d8f3df0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dfx, dfy], axis=1)\n",
    "predictor = TabularPredictor(label='label')\n",
    "predictor.fit(df, \n",
    "              hyperparameters={'GBM' : {}}, \n",
    "              feature_generator=auto_ml_pipeline_feature_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2263e-3437-4358-8c49-58fcaf40e4b8",
   "metadata": {},
   "source": [
    "B uniuqe     , <br>\n",
    "D     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71851766-1089-4ea6-b55c-c54abf82d27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(set(dfx['B'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abb1443e-ad39-4e18-ab3c-bf43bf07b660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7428.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['E']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 4 to 2 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])     : 2 | ['B', 'D']\n",
      "\t\t('datetime', [])     : 1 | ['C']\n",
      "\t\t('float', [])        : 1 | ['A']\n",
      "\t\t('object', ['text']) : 1 | ['E']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 2 | ['B', 'D']\n",
      "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
      "\t\t('float', [])                       : 1 | ['A']\n",
      "\t\t('int', ['binned', 'text_special']) : 2 | ['E.char_count', 'E.symbol_ratio. ']\n",
      "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 3 | ['__nlp__.abc', '__nlp__.ghi', '__nlp__._total_']\n",
      "\t0.1s = Fit runtime\n",
      "\t5 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>C</th>\n",
       "      <th>C.year</th>\n",
       "      <th>C.month</th>\n",
       "      <th>C.day</th>\n",
       "      <th>C.dayofweek</th>\n",
       "      <th>E.char_count</th>\n",
       "      <th>E.symbol_ratio.</th>\n",
       "      <th>__nlp__.abc</th>\n",
       "      <th>__nlp__.ghi</th>\n",
       "      <th>__nlp__._total_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545774</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.468674</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946771200000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.767960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118771</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.182318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.562761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.797270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.502741</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.056356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946512000000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A  B  D    E                   C  C.year  C.month  C.day  \\\n",
       "0  -0.545774  1  3  NaN  946684800000000000    2000        1      1   \n",
       "1  -0.468674  1  2  NaN  946771200000000000    2000        1      2   \n",
       "2   1.767960  1  0  NaN  946598400000000000    1999       12     31   \n",
       "3  -0.118771  2  3    5  946684800000000000    2000        1      1   \n",
       "4   0.630196  1  1  NaN  946598400000000000    1999       12     31   \n",
       "..       ... .. ..  ...                 ...     ...      ...    ...   \n",
       "95 -1.182318  0  0  NaN  946684800000000000    2000        1      1   \n",
       "96  0.562761  1  0  NaN  946684800000000000    2000        1      1   \n",
       "97 -0.797270  1  1  NaN  946684800000000000    2000        1      1   \n",
       "98  0.502741  1  3  NaN  946598400000000000    1999       12     31   \n",
       "99  2.056356  1  1  NaN  946512000000000000    1999       12     30   \n",
       "\n",
       "    C.dayofweek  E.char_count  E.symbol_ratio.   __nlp__.abc  __nlp__.ghi  \\\n",
       "0             5             4                 2            0            2   \n",
       "1             6             5                 1            1            2   \n",
       "2             4             3                 3            1            1   \n",
       "3             5             3                 3            1            0   \n",
       "4             4             6                 0            1            2   \n",
       "..          ...           ...               ...          ...          ...   \n",
       "95            5             4                 2            0            2   \n",
       "96            5             5                 1            1            1   \n",
       "97            5             5                 1            1            1   \n",
       "98            4             5                 1            0            0   \n",
       "99            3             6                 0            2            2   \n",
       "\n",
       "    __nlp__._total_  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 2  \n",
       "..              ...  \n",
       "95                1  \n",
       "96                2  \n",
       "97                2  \n",
       "98                0  \n",
       "99                2  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B  \n",
    "dfx[\"B\"] = dfx[\"B\"].astype(\"category\")\n",
    "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
    "auto_ml_pipeline_feature_generator.fit_transform(X=dfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401c31a-ad3a-4348-abac-e8191f11311d",
   "metadata": {},
   "source": [
    "### Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73140f74-7c34-4e41-9c8a-66f03d665e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.468674</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>x</td>\n",
       "      <td>ef ghi abc ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.767960</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>v</td>\n",
       "      <td>ef d ghi abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118771</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>y</td>\n",
       "      <td>jkl d abc ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630196</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>w</td>\n",
       "      <td>ghi ghi abc jkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A    B          C    D                E\n",
       "0       NaN  NaN        NaT  NaN              NaN\n",
       "1 -0.468674    0 2000-01-02    x   ef ghi abc ghi\n",
       "2  1.767960    0 1999-12-31    v     ef d ghi abc\n",
       "3 -0.118771    1 2000-01-01    y     jkl d abc ef\n",
       "4  0.630196    0 1999-12-31    w  ghi ghi abc jkl"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.iloc[0] = np.nan\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1544e0c1-a5fd-48a7-ad69-54168293bc77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7406.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['E']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 4 to 2 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])     : 2 | ['B', 'D']\n",
      "\t\t('datetime', [])     : 1 | ['C']\n",
      "\t\t('float', [])        : 1 | ['A']\n",
      "\t\t('object', ['text']) : 1 | ['E']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 2 | ['B', 'D']\n",
      "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
      "\t\t('float', [])                       : 1 | ['A']\n",
      "\t\t('int', ['binned', 'text_special']) : 3 | ['E.char_count', 'E.word_count', 'E.symbol_ratio. ']\n",
      "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 3 | ['__nlp__.abc', '__nlp__.ghi', '__nlp__._total_']\n",
      "\t0.1s = Fit runtime\n",
      "\t5 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>C</th>\n",
       "      <th>C.year</th>\n",
       "      <th>C.month</th>\n",
       "      <th>C.day</th>\n",
       "      <th>C.dayofweek</th>\n",
       "      <th>E.char_count</th>\n",
       "      <th>E.word_count</th>\n",
       "      <th>E.symbol_ratio.</th>\n",
       "      <th>__nlp__.abc</th>\n",
       "      <th>__nlp__.ghi</th>\n",
       "      <th>__nlp__._total_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946687418181818240</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.468674</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946771200000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.767960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118771</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.182318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.562761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.797270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.502741</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.056356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>946512000000000000</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A    B    D    E                   C  C.year  C.month  C.day  \\\n",
       "0        NaN  NaN  NaN  NaN  946687418181818240    2000        1      1   \n",
       "1  -0.468674    1    2  NaN  946771200000000000    2000        1      2   \n",
       "2   1.767960    1    0  NaN  946598400000000000    1999       12     31   \n",
       "3  -0.118771    2    3    5  946684800000000000    2000        1      1   \n",
       "4   0.630196    1    1  NaN  946598400000000000    1999       12     31   \n",
       "..       ...  ...  ...  ...                 ...     ...      ...    ...   \n",
       "95 -1.182318    0    0  NaN  946684800000000000    2000        1      1   \n",
       "96  0.562761    1    0  NaN  946684800000000000    2000        1      1   \n",
       "97 -0.797270    1    1  NaN  946684800000000000    2000        1      1   \n",
       "98  0.502741    1    3  NaN  946598400000000000    1999       12     31   \n",
       "99  2.056356    1    1  NaN  946512000000000000    1999       12     30   \n",
       "\n",
       "    C.dayofweek  E.char_count  E.word_count  E.symbol_ratio.   __nlp__.abc  \\\n",
       "0             5             0             0                 0            0   \n",
       "1             6             6             1                 2            1   \n",
       "2             4             4             1                 4            1   \n",
       "3             5             4             1                 4            1   \n",
       "4             4             7             1                 1            1   \n",
       "..          ...           ...           ...               ...          ...   \n",
       "95            5             5             1                 3            0   \n",
       "96            5             6             1                 2            1   \n",
       "97            5             6             1                 2            1   \n",
       "98            4             6             1                 2            0   \n",
       "99            3             7             1                 1            2   \n",
       "\n",
       "    __nlp__.ghi  __nlp__._total_  \n",
       "0             0                0  \n",
       "1             2                2  \n",
       "2             1                2  \n",
       "3             0                1  \n",
       "4             2                2  \n",
       "..          ...              ...  \n",
       "95            2                1  \n",
       "96            1                2  \n",
       "97            1                2  \n",
       "98            0                0  \n",
       "99            2                2  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
    "auto_ml_pipeline_feature_generator.fit_transform(X=dfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d55ebd-8c76-4827-a73d-8ec83fc47d28",
   "metadata": {},
   "source": [
    "A,B,D,E  NaN  date C   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d49f18-4b54-4a60-bbcb-a5157964b4e7",
   "metadata": {},
   "source": [
    "### Customizing of Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6664acc2-44ad-45e0-93a4-3513acf401f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.468674</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>x</td>\n",
       "      <td>ef ghi abc ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.767960</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>v</td>\n",
       "      <td>ef d ghi abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118771</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>y</td>\n",
       "      <td>jkl d abc ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630196</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>w</td>\n",
       "      <td>ghi ghi abc jkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.182318</td>\n",
       "      <td>-1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>v</td>\n",
       "      <td>ghi ef ef ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.562761</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>v</td>\n",
       "      <td>ghi abc ef jkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.797270</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>w</td>\n",
       "      <td>ef jkl ghi abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.502741</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>y</td>\n",
       "      <td>jkl jkl jkl ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.056356</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-12-30</td>\n",
       "      <td>w</td>\n",
       "      <td>abc ghi ghi abc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A    B          C    D                E\n",
       "0        NaN  NaN        NaT  NaN              NaN\n",
       "1  -0.468674    0 2000-01-02    x   ef ghi abc ghi\n",
       "2   1.767960    0 1999-12-31    v     ef d ghi abc\n",
       "3  -0.118771    1 2000-01-01    y     jkl d abc ef\n",
       "4   0.630196    0 1999-12-31    w  ghi ghi abc jkl\n",
       "..       ...  ...        ...  ...              ...\n",
       "95 -1.182318   -1 2000-01-01    v    ghi ef ef ghi\n",
       "96  0.562761    0 2000-01-01    v   ghi abc ef jkl\n",
       "97 -0.797270    0 2000-01-01    w   ef jkl ghi abc\n",
       "98  0.502741    0 1999-12-31    y   jkl jkl jkl ef\n",
       "99  2.056356    0 1999-12-30    w  abc ghi ghi abc\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "524b1e7a-6479-445b-9834-e12f054e871f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.features.generators import PipelineFeatureGenerator, CategoryFeatureGenerator, IdentityFeatureGenerator\n",
    "from autogluon.common.features.types import R_INT, R_FLOAT\n",
    "mypipeline = PipelineFeatureGenerator(\n",
    "    generators = [[        \n",
    "        CategoryFeatureGenerator(maximum_num_cat=10),  # Overridden from default.\n",
    "        IdentityFeatureGenerator(infer_features_in_args=dict(valid_raw_types=[R_INT, R_FLOAT])),\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b433f6b-fab4-42ec-925f-244742c25f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7391.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['C']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('datetime', []) : 1 | ['C']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])     : 2 | ['B', 'D']\n",
      "\t\t('float', [])        : 1 | ['A']\n",
      "\t\t('object', ['text']) : 1 | ['E']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                   : 2 | ['B', 'D']\n",
      "\t\t('category', ['text_as_category']) : 1 | ['E']\n",
      "\t\t('float', [])                      : 1 | ['A']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.468674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.767960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.118771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.182318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.797270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.056356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      B    D    E         A\n",
       "0   NaN  NaN  NaN       NaN\n",
       "1     1    2  NaN -0.468674\n",
       "2     1    0  NaN  1.767960\n",
       "3     2    3    5 -0.118771\n",
       "4     1    1  NaN  0.630196\n",
       "..  ...  ...  ...       ...\n",
       "95    0    0  NaN -1.182318\n",
       "96    1    0  NaN  0.562761\n",
       "97    1    1  NaN -0.797270\n",
       "98    1    3  NaN  0.502741\n",
       "99    1    1  NaN  2.056356\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypipeline.fit_transform(X=dfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68befb35-c65b-481f-8bfb-5b47b81f5217",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (Advanced) Tabular AutoGluon Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c147928-0e76-4c14-bdd9-377944efa655",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multi-Label Prediction\n",
    "\n",
    "### predicting Multiple columns in a Table\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-multilabel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65a0053d-e289-4fc5-8150-a478c0613a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4023754-7a86-4008-9598-d1bb90dfee40",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8b68d99-67c2-44a1-9ea1-ad5097784eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c19931-bb55-456b-97de-8b9d91320dbc",
   "metadata": {},
   "source": [
    "labels, problem_types, eval_metrics  . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eacbc85d-a7b7-43af-a5c6-09cfe23ef5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = ['education-num','education','class']  # which columns to predict based on the others\n",
    "problem_types = ['regression','multiclass','binary']  # type of each prediction problem (optional)\n",
    "eval_metrics = ['mean_absolute_error','accuracy','accuracy']  # metrics used to evaluate predictions for each label (optional)\n",
    "save_path = 'agModels-predictEducationClass'  # specifies folder to store trained models (optional)\n",
    "\n",
    "time_limit = 5  # how many seconds to train the TabularPredictor for each label, set much larger in your applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f16090b-685e-4ad3-af1d-ccb1f582cb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 5s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass/Predictor_education-num/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 12\n",
      "Label Column: education-num\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7408.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 7 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 5 | ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 4.95s of the 4.95s of remaining time.\n",
      "\t-2.086\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 4.94s of the 4.94s of remaining time.\n",
      "\t-2.1856\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 4.93s of the 4.93s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: education-num ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.7808\t = Validation score   (-mean_absolute_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 4.71s of the 4.71s of remaining time.\n",
      "\t-1.7854\t = Validation score   (-mean_absolute_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 4.51s of the 4.5s of remaining time.\n",
      "\t-1.7079\t = Validation score   (-mean_absolute_error)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 4.3s of the 4.3s of remaining time.\n",
      "\t-1.7377\t = Validation score   (-mean_absolute_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3.53s of the 3.53s of remaining time.\n",
      "\t-1.8167\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3.35s of the 3.35s of remaining time.\n",
      "\t-1.9297\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3.07s of the 3.06s of remaining time.\n",
      "\t-1.631\t = Validation score   (-mean_absolute_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 2.86s of the 2.85s of remaining time.\n",
      "\t-1.7451\t = Validation score   (-mean_absolute_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 2.05s of the 2.05s of remaining time.\n",
      "\t-1.8925\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.95s of the 1.7s of remaining time.\n",
      "\t-1.6208\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass/Predictor_education-num/\")\n",
      "Beginning AutoGluon training ... Time limit = 5s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass/Predictor_education/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 13\n",
      "Label Column: education\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 11 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.976\n",
      "Train Data Class Count: 11\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7403.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 7 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 390, Val Rows: 98\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 4.96s of the 4.96s of remaining time.\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 4.94s of the 4.94s of remaining time.\n",
      "\t0.2347\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 4.94s of the 4.94s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: education ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8163\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 4.63s of the 4.63s of remaining time.\n",
      "\t0.9694\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3.57s of the 3.57s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3.05s of the 3.05s of remaining time.\n",
      "\t0.9082\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 2.77s of the 2.77s of remaining time.\n",
      "\t0.898\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 2.52s of the 2.52s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 213.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t2.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 0.01s of the 0.01s of remaining time.\n",
      "\tWarning: Model is expected to require 0.4s to train, which exceeds the maximum time limit of 0.0s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesGini.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.96s of the -0.01s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass/Predictor_education/\")\n",
      "Beginning AutoGluon training ... Time limit = 5s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass/Predictor_class/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7389.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 4.96s of the 4.96s of remaining time.\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 4.95s of the 4.95s of remaining time.\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 4.94s of the 4.94s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: class ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 4.78s of the 4.78s of remaining time.\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 4.59s of the 4.59s of remaining time.\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 4.36s of the 4.35s of remaining time.\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 4.15s of the 4.15s of remaining time.\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3.59s of the 3.59s of remaining time.\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3.39s of the 3.39s of remaining time.\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3.19s of the 3.19s of remaining time.\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 2.89s of the 2.89s of remaining time.\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 2.76s of the 2.76s of remaining time.\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1.96s of the 1.96s of remaining time.\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.96s of the 1.57s of remaining time.\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.6s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass/Predictor_class/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels-predictEducationClass/')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, eval_metrics=eval_metrics, path=save_path)\n",
    "multi_predictor.fit(train_data, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380230c-b7d9-4da0-81b5-6424229bb82b",
   "metadata": {},
   "source": [
    "### Inference and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1692e5b5-325d-47fb-a7a9-06e06a246cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>41</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>408498</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>746786</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>50</td>\n",
       "      <td>Private</td>\n",
       "      <td>62593</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>248178</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>43</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>52849</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass  fnlwgt       marital-status        occupation  \\\n",
       "5454   41   Self-emp-not-inc  408498   Married-civ-spouse   Exec-managerial   \n",
       "6111   39            Private  746786   Married-civ-spouse    Prof-specialty   \n",
       "5282   50            Private   62593   Married-civ-spouse   Farming-fishing   \n",
       "3046   31            Private  248178   Married-civ-spouse     Other-service   \n",
       "2162   43          State-gov   52849   Married-civ-spouse    Prof-specialty   \n",
       "\n",
       "     relationship                 race    sex  capital-gain  capital-loss  \\\n",
       "5454      Husband                White   Male             0             0   \n",
       "6111      Husband                White   Male             0             0   \n",
       "5282      Husband   Asian-Pac-Islander   Male             0             0   \n",
       "3046      Husband                Black   Male             0             0   \n",
       "2162      Husband                White   Male             0             0   \n",
       "\n",
       "      hours-per-week  native-country  \n",
       "5454              50   United-States  \n",
       "6111              55   United-States  \n",
       "5282              40   United-States  \n",
       "3046              35   United-States  \n",
       "2162              40   United-States  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = test_data.sample(n=subsample_size, random_state=0)\n",
    "test_data_nolab = test_data.drop(columns=labels)  # unnecessary, just to demonstrate we're not cheating here\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e268bf9-b79b-401e-bb2a-6f119c2e9a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: education-num ...\n",
      "Predicting with TabularPredictor for label: education ...\n",
      "Predicting with TabularPredictor for label: class ...\n",
      "Predictions:  \n",
      "       education-num      education   class\n",
      "5454      10.314816   Some-college    >50K\n",
      "6111      13.340745      Bachelors    >50K\n",
      "5282       9.820933        HS-grad   <=50K\n",
      "3046       9.638832        HS-grad   <=50K\n",
      "2162      12.913060        HS-grad    >50K\n",
      "...             ...            ...     ...\n",
      "6965       9.444245        HS-grad    >50K\n",
      "4762       8.696204           11th   <=50K\n",
      "234       10.413758   Some-college   <=50K\n",
      "6291      10.391630   Some-college   <=50K\n",
      "9575      10.274948   Some-college    >50K\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained multilabel predictor from file\n",
    "\n",
    "predictions = multi_predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f567a59-fb48-4da4-85c4-ee9b58f2fe4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1420: FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "  warnings.warn(\n",
      "Evaluation: mean_absolute_error on test data: -1.6336145429611206\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -1.6336145429611206,\n",
      "    \"root_mean_squared_error\": -2.198722579088362,\n",
      "    \"mean_squared_error\": -4.834380979792979,\n",
      "    \"r2\": 0.3748938437982332,\n",
      "    \"pearsonr\": 0.6188337473117967,\n",
      "    \"median_absolute_error\": -1.224937915802002\n",
      "}\n",
      "Evaluation: accuracy on test data: 0.218\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.218,\n",
      "    \"balanced_accuracy\": 0.08682331905790826,\n",
      "    \"mcc\": 0.03233013068324609\n",
      "}\n",
      "Evaluation: accuracy on test data: 0.84\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.84,\n",
      "    \"balanced_accuracy\": 0.7303746421780648,\n",
      "    \"mcc\": 0.5471381005232028,\n",
      "    \"roc_auc\": 0.85346538791032,\n",
      "    \"f1\": 0.6190476190476191,\n",
      "    \"precision\": 0.8024691358024691,\n",
      "    \"recall\": 0.5038759689922481\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: education-num ...\n",
      "Evaluating TabularPredictor for label: education ...\n",
      "Evaluating TabularPredictor for label: class ...\n",
      "{'education-num': {'mean_absolute_error': -1.6336145429611206, 'root_mean_squared_error': -2.198722579088362, 'mean_squared_error': -4.834380979792979, 'r2': 0.3748938437982332, 'pearsonr': 0.6188337473117967, 'median_absolute_error': -1.224937915802002}, 'education': {'accuracy': 0.218, 'balanced_accuracy': 0.08682331905790826, 'mcc': 0.03233013068324609}, 'class': {'accuracy': 0.84, 'balanced_accuracy': 0.7303746421780648, 'mcc': 0.5471381005232028, 'roc_auc': 0.85346538791032, 'f1': 0.6190476190476191, 'precision': 0.8024691358024691, 'recall': 0.5038759689922481}}\n",
      "Evaluated using metrics: {'education-num': 'mean_absolute_error', 'education': 'accuracy', 'class': 'accuracy'}\n"
     ]
    }
   ],
   "source": [
    "evaluations = multi_predictor.evaluate(test_data)\n",
    "print(evaluations)\n",
    "print(\"Evaluated using metrics:\", multi_predictor.eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7bfb7-8db1-40a2-b44c-bb151bcfcab8",
   "metadata": {},
   "source": [
    "### Accessing the TabularPredictor for One Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "95510f12-bb08-45eb-9233-8e537f732cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-1.620802</td>\n",
       "      <td>0.024199</td>\n",
       "      <td>1.473809</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.070705</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-1.631029</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-1.707900</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>0.182843</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>0.182843</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-1.737659</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.770317</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.770317</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-1.745082</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.801264</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.801264</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-1.780762</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.215174</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.215174</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-1.785416</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-1.816733</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>0.152974</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>0.152974</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-1.892534</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.338026</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.338026</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-1.929672</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.277434</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.277434</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-2.086000</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-2.185627</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val  fit_time  \\\n",
       "0   WeightedEnsemble_L2  -1.620802       0.024199  1.473809   \n",
       "1               XGBoost  -1.631029       0.001897  0.203823   \n",
       "2       RandomForestMSE  -1.707900       0.016527  0.182843   \n",
       "3              CatBoost  -1.737659       0.001799  0.770317   \n",
       "4        NeuralNetTorch  -1.745082       0.003626  0.801264   \n",
       "5            LightGBMXT  -1.780762       0.002007  0.215174   \n",
       "6              LightGBM  -1.785416       0.001803  0.200820   \n",
       "7         ExtraTreesMSE  -1.816733       0.014317  0.152974   \n",
       "8         LightGBMLarge  -1.892534       0.001783  0.338026   \n",
       "9       NeuralNetFastAI  -1.929672       0.003660  0.277434   \n",
       "10       KNeighborsUnif  -2.086000       0.004509  0.003940   \n",
       "11       KNeighborsDist  -2.185627       0.003164  0.002969   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000142           0.070705            2       True   \n",
       "1                 0.001897           0.203823            1       True   \n",
       "2                 0.016527           0.182843            1       True   \n",
       "3                 0.001799           0.770317            1       True   \n",
       "4                 0.003626           0.801264            1       True   \n",
       "5                 0.002007           0.215174            1       True   \n",
       "6                 0.001803           0.200820            1       True   \n",
       "7                 0.014317           0.152974            1       True   \n",
       "8                 0.001783           0.338026            1       True   \n",
       "9                 0.003660           0.277434            1       True   \n",
       "10                0.004509           0.003940            1       True   \n",
       "11                0.003164           0.002969            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          12  \n",
       "1           9  \n",
       "2           5  \n",
       "3           6  \n",
       "4          10  \n",
       "5           3  \n",
       "6           4  \n",
       "7           7  \n",
       "8          11  \n",
       "9           8  \n",
       "10          1  \n",
       "11          2  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_predictor.get_predictor('education-num').leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97bfc65a-49b3-40ca-b88f-da24bb42899f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>2.505106</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>2.505106</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.512164</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.512164</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.602399</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.090235</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>1.004710</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>1.004710</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.244683</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.244683</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.229140</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.229140</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.301394</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.301394</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.234694</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val  pred_time_val  fit_time  \\\n",
       "0             CatBoost   1.000000       0.001956  2.505106   \n",
       "1             LightGBM   1.000000       0.002955  0.512164   \n",
       "2  WeightedEnsemble_L2   1.000000       0.003144  0.602399   \n",
       "3           LightGBMXT   0.969388       0.004205  1.004710   \n",
       "4     RandomForestGini   0.908163       0.018387  0.244683   \n",
       "5     RandomForestEntr   0.897959       0.017997  0.229140   \n",
       "6      NeuralNetFastAI   0.816327       0.003726  0.301394   \n",
       "7       KNeighborsUnif   0.265306       0.005394  0.004069   \n",
       "8       KNeighborsDist   0.234694       0.002665  0.003351   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.001956           2.505106            1       True   \n",
       "1                0.002955           0.512164            1       True   \n",
       "2                0.000189           0.090235            2       True   \n",
       "3                0.004205           1.004710            1       True   \n",
       "4                0.018387           0.244683            1       True   \n",
       "5                0.017997           0.229140            1       True   \n",
       "6                0.003726           0.301394            1       True   \n",
       "7                0.005394           0.004069            1       True   \n",
       "8                0.002665           0.003351            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          8  \n",
       "1          5  \n",
       "2          9  \n",
       "3          4  \n",
       "4          6  \n",
       "5          7  \n",
       "6          3  \n",
       "7          1  \n",
       "8          2  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_predictor.get_predictor('education').leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f634a6bd-003c-447f-811c-d350764c0661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.555203</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.555203</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.186465</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.186465</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.346392</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.159927</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.791422</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.791422</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.015179</td>\n",
       "      <td>0.211425</td>\n",
       "      <td>0.015179</td>\n",
       "      <td>0.211425</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.372655</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.372655</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.156718</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.156718</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.295996</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.295996</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.015778</td>\n",
       "      <td>0.177732</td>\n",
       "      <td>0.015778</td>\n",
       "      <td>0.177732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.178309</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.178309</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val  fit_time  \\\n",
       "0              CatBoost       0.85       0.001981  0.555203   \n",
       "1               XGBoost       0.85       0.002079  0.125008   \n",
       "2              LightGBM       0.85       0.002153  0.186465   \n",
       "3   WeightedEnsemble_L2       0.85       0.002420  0.346392   \n",
       "4        NeuralNetTorch       0.84       0.003904  0.791422   \n",
       "5      RandomForestGini       0.84       0.015179  0.211425   \n",
       "6         LightGBMLarge       0.83       0.002223  0.372655   \n",
       "7            LightGBMXT       0.83       0.002410  0.156718   \n",
       "8      RandomForestEntr       0.83       0.014635  0.180579   \n",
       "9       NeuralNetFastAI       0.82       0.004322  0.295996   \n",
       "10       ExtraTreesGini       0.82       0.015778  0.177732   \n",
       "11       ExtraTreesEntr       0.81       0.015788  0.178309   \n",
       "12       KNeighborsUnif       0.73       0.004022  0.003847   \n",
       "13       KNeighborsDist       0.65       0.003409  0.002838   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001981           0.555203            1       True   \n",
       "1                 0.002079           0.125008            1       True   \n",
       "2                 0.002153           0.186465            1       True   \n",
       "3                 0.000267           0.159927            2       True   \n",
       "4                 0.003904           0.791422            1       True   \n",
       "5                 0.015179           0.211425            1       True   \n",
       "6                 0.002223           0.372655            1       True   \n",
       "7                 0.002410           0.156718            1       True   \n",
       "8                 0.014635           0.180579            1       True   \n",
       "9                 0.004322           0.295996            1       True   \n",
       "10                0.015778           0.177732            1       True   \n",
       "11                0.015788           0.178309            1       True   \n",
       "12                0.004022           0.003847            1       True   \n",
       "13                0.003409           0.002838            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           7  \n",
       "1          11  \n",
       "2           4  \n",
       "3          14  \n",
       "4          12  \n",
       "5           5  \n",
       "6          13  \n",
       "7           3  \n",
       "8           6  \n",
       "9          10  \n",
       "10          8  \n",
       "11          9  \n",
       "12          1  \n",
       "13          2  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_class = multi_predictor.get_predictor('class')\n",
    "predictor_class.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee3471-9f5c-41d4-be36-a985ff3fc34b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Trainig models with GPU support\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-gpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b5b7713-d5f8-4aa9-9f0f-c09255d8c95b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_090837/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_090837/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7447.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 391, Val Rows: 98\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.1633\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.1224\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.3571\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.3673\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.3469\t = Validation score   (accuracy)\n",
      "\t9.95s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.3163\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t0.2653\t = Validation score   (accuracy)\n",
      "\t3.56s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4388\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_090837/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data,\n",
    "    num_gpus=1,  # Grant 1 gpu for the entire Tabular Predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd87b93-ad1b-4251-b0ee-674344c6249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'GBM': [\n",
    "        {'ag_args_fit': {'num_gpus': 0}},  # Train with CPU\n",
    "        {'ag_args_fit': {'num_gpus': 1}}   # Train with GPU. This amount needs to be <= total num_gpus granted to TabularPredictor\n",
    "    ]\n",
    "}\n",
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data, \n",
    "    num_gpus=1,\n",
    "    hyperparameters=hyperparameters, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ba051-9b8f-449c-8195-99f70f287e96",
   "metadata": {},
   "source": [
    "### advanced resource allocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551fe93-6e12-4b41-b168-be251e989ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit(\n",
    "    num_cpus=32,\n",
    "    num_gpus=4,\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': {},\n",
    "    },\n",
    "    num_bag_folds=2,\n",
    "    ag_args_ensemble={\n",
    "        'ag_args_fit': {\n",
    "            'num_cpus': 10,\n",
    "            'num_gpus': 2,\n",
    "        }\n",
    "    },\n",
    "    'ag_args_fit': {\n",
    "        'num_cpus': 4,\n",
    "        'num_gpus': 0.5,\n",
    "    }\n",
    "    hyperparameter_tune_kwargs={\n",
    "        'searcher': 'random',\n",
    "        'scheduler': 'local',\n",
    "        'num_trials: 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4868c-ff86-432e-abce-dd6dda36a8c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Adding a custom metric to Autogluon\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-custom-metric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cef0bee8-a8a8-45e7-b2fe-2e5c188212e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0 1 1 0 1 1 1 1 1 1]\n",
      "y_pred: [1 0 0 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = np.random.randint(low=0, high=2, size=10)\n",
    "y_pred = np.random.randint(low=0, high=2, size=10)\n",
    "\n",
    "print(f'y_true: {y_true}')\n",
    "print(f'y_pred: {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa0fa169-eaee-41e9-9f3d-384f4e7c4f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "sklearn.metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a51eaec6-5b01-45c5-a5e1-9f52c99a86b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.core.metrics import make_scorer\n",
    "\n",
    "ag_accuracy_scorer = make_scorer(name='accuracy',\n",
    "                                 score_func=sklearn.metrics.accuracy_score,\n",
    "                                 optimum=1,\n",
    "                                 greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c7ca4-18d6-40a4-8b85-8141dd9adac2",
   "metadata": {},
   "source": [
    "### Custom Mean Squared Error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "44bc081a-907e-4fcf-927f-d5126e448307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0.79172504 0.52889492 0.56804456 0.92559664 0.07103606 0.0871293\n",
      " 0.0202184  0.83261985 0.77815675 0.87001215]\n",
      "y_pred: [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443 0.63992102\n",
      " 0.14335329 0.94466892 0.52184832 0.41466194]\n"
     ]
    }
   ],
   "source": [
    "y_true = np.random.rand(10)\n",
    "y_pred = np.random.rand(10)\n",
    "\n",
    "print(f'y_true: {y_true}')\n",
    "print(f'y_pred: {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd1ddf95-bc52-4ce2-b228-84c4761491e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07489374242602942"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79ddbbe9-41d3-41b9-b68d-50757b321ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_mean_squared_error_scorer = make_scorer(name='mean_squared_error',\n",
    "                                           score_func=sklearn.metrics.mean_squared_error,\n",
    "                                           optimum=0,\n",
    "                                           greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34596767-9ee6-486c-88bc-441713184c25",
   "metadata": {},
   "source": [
    "### making func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75d35462-ed6b-4861-b98b-a399d9de9aac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07489374242602942"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_func(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "mse_func(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "426ba2f7-d193-4188-9971-4f29f063a999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07489374242602942"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_mean_squared_error_custom_scorer = make_scorer(name='mean_squared_error',\n",
    "                                                  score_func=mse_func,\n",
    "                                                  optimum=0,\n",
    "                                                  greater_is_better=False)\n",
    "ag_mean_squared_error_custom_scorer(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc35ba-51db-4396-be3c-7069fcc00de3",
   "metadata": {},
   "source": [
    "### Using Custom Metric in TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b877b7a-34b8-46e2-80af-08da9e039c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n",
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')  # can be local CSV file as well, returns Pandas DataFrame\n",
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')  # another Pandas DataFrame\n",
    "label = 'class'  # specifies which column we want to predict\n",
    "train_data = train_data.sample(n=1000, random_state=0)  # subsample dataset for faster demo\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a67e7268-6398-4f44-9a4a-cda3ce9a174b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_091158/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_091158/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7414.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.59 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "Fitting 4 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.77\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.815\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.57s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_091158/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.075710</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.055892</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.831917</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.052639</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.260721</td>\n",
       "      <td>0.052639</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.260721</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.780940</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.115073</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.115073</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              XGBoost    0.847784      0.840        0.016339       0.002301   \n",
       "1             CatBoost    0.842768      0.860        0.008550       0.002246   \n",
       "2  WeightedEnsemble_L2    0.842768      0.860        0.009629       0.002559   \n",
       "3       NeuralNetTorch    0.831917      0.815        0.052639       0.006049   \n",
       "4             LightGBM    0.780940      0.770        0.006437       0.002364   \n",
       "\n",
       "   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  0.034474                 0.016339                0.002301   \n",
       "1  0.019817                 0.008550                0.002246   \n",
       "2  0.075710                 0.001079                0.000314   \n",
       "3  0.260721                 0.052639                0.006049   \n",
       "4  0.115073                 0.006437                0.002364   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.034474            1       True          3  \n",
       "1           0.019817            1       True          2  \n",
       "2           0.055892            2       True          5  \n",
       "3           0.260721            1       True          4  \n",
       "4           0.115073            1       True          1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(label=label).fit(train_data, hyperparameters='toy')\n",
    "\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d03b8485-1ad1-4ed5-b72b-a772b00366e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.075710</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.055892</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.831917</td>\n",
       "      <td>0.831917</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.260721</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.260721</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.780940</td>\n",
       "      <td>0.780940</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.115073</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.115073</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  accuracy  score_val  pred_time_test  \\\n",
       "0              XGBoost    0.847784  0.847784      0.840        0.019465   \n",
       "1             CatBoost    0.842768  0.842768      0.860        0.008188   \n",
       "2  WeightedEnsemble_L2    0.842768  0.842768      0.860        0.009149   \n",
       "3       NeuralNetTorch    0.831917  0.831917      0.815        0.052139   \n",
       "4             LightGBM    0.780940  0.780940      0.770        0.005682   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.002301  0.034474                 0.019465                0.002301   \n",
       "1       0.002246  0.019817                 0.008188                0.002246   \n",
       "2       0.002559  0.075710                 0.000961                0.000314   \n",
       "3       0.006049  0.260721                 0.052139                0.006049   \n",
       "4       0.002364  0.115073                 0.005682                0.002364   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.034474            1       True          3  \n",
       "1           0.019817            1       True          2  \n",
       "2           0.055892            2       True          5  \n",
       "3           0.260721            1       True          4  \n",
       "4           0.115073            1       True          1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, extra_metrics=[ ag_accuracy_scorer], silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18562f2-5c1a-4f20-9920-1a6617d5c70f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Adding a custom model to AutoGluon\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-custom-model-advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15bdcc8-70a7-47ef-b7d2-c1c191db731d",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "faf31b92-bde4-4a68-8dc6-135dc1e357d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n",
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')  # can be local CSV file as well, returns Pandas DataFrame\n",
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')  # another Pandas DataFrame\n",
    "label = 'class'  # specifies which column do we want to predict\n",
    "train_data = train_data.sample(n=1000, random_state=0)  # subsample for faster demo\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a089e6d-ed55-4817-9759-ee3f619d23d7",
   "metadata": {},
   "source": [
    "### Force features to not be dropped in model-specific preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2dac0397-3cdf-4e1a-a43b-97f99016fbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.core.models import AbstractModel\n",
    "\n",
    "class DummyModel(AbstractModel):\n",
    "    def _fit(self, X, **kwargs):\n",
    "        print(f'Before {self.__class__.__name__} Preprocessing ({len(X.columns)} features):\\n\\t{list(X.columns)}')\n",
    "        X = self.preprocess(X)\n",
    "        print(f'After  {self.__class__.__name__} Preprocessing ({len(X.columns)} features):\\n\\t{list(X.columns)}')\n",
    "        print(X.head(5))\n",
    "\n",
    "class DummyModelKeepUnique(DummyModel):\n",
    "    def _get_default_auxiliary_params(self) -> dict:\n",
    "        default_auxiliary_params = super()._get_default_auxiliary_params()\n",
    "        extra_auxiliary_params = dict(\n",
    "            drop_unique=False,  # Whether to drop features that have only 1 unique value, default is True\n",
    "        )\n",
    "        default_auxiliary_params.update(extra_auxiliary_params)\n",
    "        return default_auxiliary_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e9b9dac9-6fbe-4e10-ad77-d95be2522afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WARNING: To use this in practice, you must put this code in a separate python file\n",
    "#  from the main process and import it or else it will not be serializable.)\n",
    "from autogluon.features import BulkFeatureGenerator, AutoMLPipelineFeatureGenerator, IdentityFeatureGenerator\n",
    "\n",
    "\n",
    "class CustomFeatureGeneratorWithUserOverride(BulkFeatureGenerator):\n",
    "    def __init__(self, automl_generator_kwargs: dict = None, **kwargs):\n",
    "        generators = self._get_default_generators(automl_generator_kwargs=automl_generator_kwargs)\n",
    "        super().__init__(generators=generators, **kwargs)\n",
    "\n",
    "    def _get_default_generators(self, automl_generator_kwargs: dict = None):\n",
    "        if automl_generator_kwargs is None:\n",
    "            automl_generator_kwargs = dict()\n",
    "\n",
    "        generators = [\n",
    "            [\n",
    "                # Preprocessing logic that handles normal features\n",
    "                AutoMLPipelineFeatureGenerator(banned_feature_special_types=['user_override'], **automl_generator_kwargs),\n",
    "\n",
    "                # Preprocessing logic that handles special features user wishes to treat separately, here we simply skip preprocessing for these features.\n",
    "                IdentityFeatureGenerator(infer_features_in_args=dict(required_special_types=['user_override'])),\n",
    "            ],\n",
    "        ]\n",
    "        return generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6c1765f8-301c-49a0-9f11-fb9faf30d49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before inserting overrides:\n",
      "('int', [])    :  6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('object', []) : 10 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "After inserting overrides:\n",
      "('int', [])                   : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "('int', ['user_override'])    : 1 | ['age']\n",
      "('object', [])                : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('object', ['user_override']) : 2 | ['native-country', 'dummy_feature']\n"
     ]
    }
   ],
   "source": [
    "# add a useless dummy feature to show that it is not dropped in preprocessing\n",
    "train_data['dummy_feature'] = 'dummy value'\n",
    "test_data['dummy_feature'] = 'dummy value'\n",
    "\n",
    "from autogluon.tabular import FeatureMetadata\n",
    "feature_metadata = FeatureMetadata.from_df(train_data)\n",
    "\n",
    "print('Before inserting overrides:')\n",
    "print(feature_metadata)\n",
    "\n",
    "feature_metadata = feature_metadata.add_special_types(\n",
    "    {\n",
    "        'age': ['user_override'],\n",
    "        'native-country': ['user_override'],\n",
    "        'dummy_feature': ['user_override'],\n",
    "    }\n",
    ")\n",
    "\n",
    "print('After inserting overrides:')\n",
    "print(feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed87964-ef79-42a8-8c0c-3327578d6a14",
   "metadata": {},
   "source": [
    "### put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "998a1673-b663-455f-9be9-d4460ea4610c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Fitting CustomFeatureGeneratorWithUserOverride...\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AutoMLPipelineFeatureGenerator...\n",
      "\t\t\tAvailable Memory:                    7377.36 MB\n",
      "\t\t\tTrain Data (Original)  Memory Usage: 0.66 MB (0.0% of available memory)\n",
      "\t\t\tStage 1 Generators:\n",
      "\t\t\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tStage 2 Generators:\n",
      "\t\t\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tStage 3 Generators:\n",
      "\t\t\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\tStage 4 Generators:\n",
      "\t\t\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\t\tFitting IdentityFeatureGenerator...\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X = train_data.drop(columns=[label])\n",
    "y = train_data[label]\n",
    "X_test = test_data.drop(columns=[label])\n",
    "y_test = test_data[label]\n",
    "\n",
    "# preprocess the label column, as done in the prior custom model tutorial\n",
    "from autogluon.core.data import LabelCleaner\n",
    "from autogluon.core.utils import infer_problem_type\n",
    "# Construct a LabelCleaner to neatly convert labels to float/integers during model training/inference, can also use to inverse_transform back to original.\n",
    "problem_type = infer_problem_type(y=y)  # Infer problem type (or else specify directly)\n",
    "label_cleaner = LabelCleaner.construct(problem_type=problem_type, y=y)\n",
    "y_preprocessed = label_cleaner.transform(y)\n",
    "y_test_preprocessed = label_cleaner.transform(y_test)\n",
    "\n",
    "# Make sure to specify your custom feature metadata to the feature generator\n",
    "my_custom_feature_generator = CustomFeatureGeneratorWithUserOverride(feature_metadata_in=feature_metadata)\n",
    "\n",
    "X_preprocessed = my_custom_feature_generator.fit_transform(X)\n",
    "X_test_preprocessed = my_custom_feature_generator.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8b841120-fffc-42bc-b599-50803290aec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fnlwgt', 'education-num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'age', 'native-country', 'dummy_feature']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>native-country</th>\n",
       "      <th>dummy_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>39264</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>United-States</td>\n",
       "      <td>dummy value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>51662</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>United-States</td>\n",
       "      <td>dummy value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>326310</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>dummy value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>222450</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>dummy value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>109190</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>United-States</td>\n",
       "      <td>dummy value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fnlwgt  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "6118    39264             10    0             0             0              40   \n",
       "23204   51662              6    0             0             0               8   \n",
       "29590  326310             10    1             0             0              44   \n",
       "18116  222450              9    1             0          2339              40   \n",
       "33964  109190             13    1         15024             0              40   \n",
       "\n",
       "      workclass education marital-status occupation relationship race  age  \\\n",
       "6118          3        14              1          4            5    4   51   \n",
       "23204         3         0              1          8            5    4   58   \n",
       "29590         3        14              1          3            0    4   40   \n",
       "18116         3        11              3         12            1    4   37   \n",
       "33964         3         9              1          4            0    4   62   \n",
       "\n",
       "       native-country dummy_feature  \n",
       "6118    United-States   dummy value  \n",
       "23204   United-States   dummy value  \n",
       "29590   United-States   dummy value  \n",
       "18116     El-Salvador   dummy value  \n",
       "33964   United-States   dummy value  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(X_preprocessed.columns))\n",
    "X_preprocessed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "008ba28b-b542-4459-b06d-fa4984d5442a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No name was specified for model, defaulting to class name: DummyModel\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_091456/DummyModel/\"\n",
      "Warning: No path was specified for model, defaulting to: AutogluonModels/ag-20230606_091456/\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Model DummyModel's eval_metric inferred to be 'accuracy' because problem_type='binary' and eval_metric was not specified during init.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DummyModel Preprocessing (15 features):\n",
      "\t['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'dummy_feature']\n",
      "After  DummyModel Preprocessing (14 features):\n",
      "\t['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country  \n",
      "6118              0             0              40   United-States  \n",
      "23204             0             0               8   United-States  \n",
      "29590             0             0              44   United-States  \n",
      "18116             0          2339              40     El-Salvador  \n",
      "33964         15024             0              40   United-States  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DummyModel at 0x32b581240>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model = DummyModel()\n",
    "dummy_model.fit(X=X, y=y, feature_metadata=my_custom_feature_generator.feature_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f74f8ee-c18b-4b7d-a4b8-fe55462b932f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No name was specified for model, defaulting to class name: DummyModelKeepUnique\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_091504/DummyModelKeepUnique/\"\n",
      "Warning: No path was specified for model, defaulting to: AutogluonModels/ag-20230606_091504/\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Model DummyModelKeepUnique's eval_metric inferred to be 'accuracy' because problem_type='binary' and eval_metric was not specified during init.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DummyModelKeepUnique Preprocessing (15 features):\n",
      "\t['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'dummy_feature']\n",
      "After  DummyModelKeepUnique Preprocessing (15 features):\n",
      "\t['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'dummy_feature']\n",
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country  \\\n",
      "6118              0             0              40   United-States   \n",
      "23204             0             0               8   United-States   \n",
      "29590             0             0              44   United-States   \n",
      "18116             0          2339              40     El-Salvador   \n",
      "33964         15024             0              40   United-States   \n",
      "\n",
      "      dummy_feature  \n",
      "6118    dummy value  \n",
      "23204   dummy value  \n",
      "29590   dummy value  \n",
      "18116   dummy value  \n",
      "33964   dummy value  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DummyModelKeepUnique at 0x32b448100>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model_keep_unique = DummyModelKeepUnique()\n",
    "dummy_model_keep_unique.fit(X=X, y=y, feature_metadata=my_custom_feature_generator.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31427c-732b-45b7-9f6a-3eb85381958c",
   "metadata": {},
   "source": [
    "### Keeping Features via TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9d861658-a6ca-4002-bf05-3b2d5e6b63d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230606_091523/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230606_091523/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 15\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting CustomFeatureGeneratorWithUserOverride...\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AutoMLPipelineFeatureGenerator...\n",
      "\t\t\tAvailable Memory:                    7382.19 MB\n",
      "\t\t\tTrain Data (Original)  Memory Usage: 0.65 MB (0.0% of available memory)\n",
      "\t\t\tStage 1 Generators:\n",
      "\t\t\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tStage 2 Generators:\n",
      "\t\t\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tStage 3 Generators:\n",
      "\t\t\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\tStage 4 Generators:\n",
      "\t\t\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "Custom Model Type Detected: <class '__main__.DummyModel'>\n",
      "Custom Model Type Detected: <class '__main__.DummyModelKeepUnique'>\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: DummyModel ...\n",
      "\tWarning: Exception caused DummyModel to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'predict_proba'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1524, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 803, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 821, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "AttributeError: 'NoneType' object has no attribute 'predict_proba'\n",
      "Fitting model: DummyModelKeepUnique ...\n",
      "\tWarning: Exception caused DummyModelKeepUnique to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'predict_proba'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1524, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 803, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/byeongsikbu/opt/anaconda3/envs/dct/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 821, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "AttributeError: 'NoneType' object has no attribute 'predict_proba'\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.41s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230606_091523/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DummyModel Preprocessing (15 features):\n",
      "\t['fnlwgt', 'education-num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'age', 'native-country', 'dummy_feature']\n",
      "After  DummyModel Preprocessing (14 features):\n",
      "\t['fnlwgt', 'education-num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'age', 'native-country']\n",
      "       fnlwgt  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "20453  369027              9    1             0             0              37   \n",
      "9855   102766             10    1             0             0              40   \n",
      "21144  141645             10    0             0             0              40   \n",
      "22391   64520              9    1             0             0              55   \n",
      "16793  193820             14    0             0             0              40   \n",
      "\n",
      "      workclass education marital-status occupation relationship race  age  \\\n",
      "20453         3        11              1         14            0    2   31   \n",
      "9855          3        14              0          3            3    4   21   \n",
      "21144         3        14              4          4            1    2   51   \n",
      "22391         3        11              3         12            1    4   21   \n",
      "16793         3        12              3         10            3    4   25   \n",
      "\n",
      "       native-country  \n",
      "20453   United-States  \n",
      "9855    United-States  \n",
      "21144   United-States  \n",
      "22391   United-States  \n",
      "16793   United-States  \n",
      "Before DummyModelKeepUnique Preprocessing (15 features):\n",
      "\t['fnlwgt', 'education-num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'age', 'native-country', 'dummy_feature']\n",
      "After  DummyModelKeepUnique Preprocessing (15 features):\n",
      "\t['fnlwgt', 'education-num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'age', 'native-country', 'dummy_feature']\n",
      "       fnlwgt  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "20453  369027              9    1             0             0              37   \n",
      "9855   102766             10    1             0             0              40   \n",
      "21144  141645             10    0             0             0              40   \n",
      "22391   64520              9    1             0             0              55   \n",
      "16793  193820             14    0             0             0              40   \n",
      "\n",
      "      workclass education marital-status occupation relationship race  age  \\\n",
      "20453         3        11              1         14            0    2   31   \n",
      "9855          3        14              0          3            3    4   21   \n",
      "21144         3        14              4          4            1    2   51   \n",
      "22391         3        11              3         12            1    4   21   \n",
      "16793         3        12              3         10            3    4   25   \n",
      "\n",
      "       native-country dummy_feature  \n",
      "20453   United-States   dummy value  \n",
      "9855    United-States   dummy value  \n",
      "21144   United-States   dummy value  \n",
      "22391   United-States   dummy value  \n",
      "16793   United-States   dummy value  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x32b580af0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "feature_generator = CustomFeatureGeneratorWithUserOverride()\n",
    "predictor = TabularPredictor(label=label)\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    feature_metadata=feature_metadata,  # feature metadata with your overrides\n",
    "    feature_generator=feature_generator,  # your custom feature generator that handles the overrides\n",
    "    hyperparameters={\n",
    "        'GBM': {},  # Can fit your custom model alongside default models\n",
    "        DummyModel: {},  # Will drop dummy_feature\n",
    "        DummyModelKeepUnique: {},  # Will not drop dummy_feature\n",
    "        # DummyModel: {'ag_args_fit': {'drop_unique': False}},  # This is another way to get same result as using DummyModelKeepUnique\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04e804-148b-4ef4-8219-03a9489809a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deployment Optimization\n",
    "\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-deployment.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bd28ce80-6d4a-4e9e-b1ca-444539a22332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "label = 'class'\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "57c25db9-fa9e-41cf-a952-72fa20bc44db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictClass-deployment/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7399.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.77s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass-deployment/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass-deployment'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "290d5d64-b61b-428b-b2b8-f0030eff4b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "0             0             0              20   United-States   <=50K  \n",
       "1             0             0              45   United-States   <=50K  \n",
       "2             0          1887              60   United-States    >50K  \n",
       "3             0             0              30   United-States   <=50K  \n",
       "4             0             0              20   United-States   <=50K  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a13207bd-0380-4ebb-b1f7-59d929f469a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2         >50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7410c266-7dc4-40a7-8942-deb4dbc862b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.087561</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>0.087561</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.456426</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.167088</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.089456</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>0.089456</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.824035</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.030659</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.030659</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.008137</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.008137</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              CatBoost    0.842461       0.85        0.009499       0.001961   \n",
       "1               XGBoost    0.842461       0.85        0.019269       0.002214   \n",
       "2      RandomForestGini    0.842461       0.84        0.085714       0.016358   \n",
       "3      RandomForestEntr    0.840925       0.83        0.087561       0.016415   \n",
       "4              LightGBM    0.839799       0.85        0.012322       0.002591   \n",
       "5   WeightedEnsemble_L2    0.839799       0.85        0.014513       0.002865   \n",
       "6            LightGBMXT    0.836421       0.83        0.008205       0.003748   \n",
       "7        ExtraTreesGini    0.834374       0.82        0.089456       0.016779   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.089109       0.016200   \n",
       "9         LightGBMLarge    0.828949       0.83        0.016730       0.002476   \n",
       "10       NeuralNetTorch    0.824035       0.84        0.030659       0.005727   \n",
       "11      NeuralNetFastAI    0.823626       0.82        0.057270       0.005454   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.008796       0.003972   \n",
       "13       KNeighborsDist    0.695158       0.65        0.008137       0.004278   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.604667                 0.009499                0.001961   \n",
       "1   0.127821                 0.019269                0.002214   \n",
       "2   0.220086                 0.085714                0.016358   \n",
       "3   0.201911                 0.087561                0.016415   \n",
       "4   0.289338                 0.012322                0.002591   \n",
       "5   0.456426                 0.002191                0.000274   \n",
       "6   0.169393                 0.008205                0.003748   \n",
       "7   0.178069                 0.089456                0.016779   \n",
       "8   0.194355                 0.089109                0.016200   \n",
       "9   0.519117                 0.016730                0.002476   \n",
       "10  0.590476                 0.030659                0.005727   \n",
       "11  0.289229                 0.057270                0.005454   \n",
       "12  0.003094                 0.008796                0.003972   \n",
       "13  0.003599                 0.008137                0.004278   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.604667            1       True          7  \n",
       "1            0.127821            1       True         11  \n",
       "2            0.220086            1       True          5  \n",
       "3            0.201911            1       True          6  \n",
       "4            0.289338            1       True          4  \n",
       "5            0.167088            2       True         14  \n",
       "6            0.169393            1       True          3  \n",
       "7            0.178069            1       True          8  \n",
       "8            0.194355            1       True          9  \n",
       "9            0.519117            1       True         13  \n",
       "10           0.590476            1       True         12  \n",
       "11           0.289229            1       True         10  \n",
       "12           0.003094            1       True          1  \n",
       "13           0.003599            1       True          2  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad26a9-1af8-4b21-b22e-e1b667aea111",
   "metadata": {},
   "source": [
    "### Snapshot a Predictor with .clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce4b9631-4b8e-437d-8182-9f6a7cf2c6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloned TabularPredictor located in 'agModels-predictClass-deployment/' to 'agModels-predictClass-deployment-clone'.\n",
      "\tTo load the cloned predictor: predictor_clone = TabularPredictor.load(path=\"agModels-predictClass-deployment-clone\")\n"
     ]
    }
   ],
   "source": [
    "save_path_clone = save_path + '-clone'\n",
    "# will return the path to the cloned predictor, identical to save_path_clone\n",
    "path_clone = predictor.clone(path=save_path_clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3fe8e934-8966-4843-9af6-90ce2dddb269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_clone = TabularPredictor.load(path=path_clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2d89f347-4812-46ee-86d6-ea086fe206a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2         >50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_clone = predictor.predict(test_data)\n",
    "y_pred_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9d460446-2bde-4b89-8624-81b2ada6afb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.equals(y_pred_clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e46eb030-5d7c-41a7-922f-acbce29411db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.018567</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>0.018567</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.098795</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>0.098795</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.072902</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>0.072902</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.456426</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.167088</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.095408</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.095408</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.824035</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.070544</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>0.070544</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              CatBoost    0.842461       0.85        0.008821       0.001961   \n",
       "1               XGBoost    0.842461       0.85        0.018567       0.002214   \n",
       "2      RandomForestGini    0.842461       0.84        0.098795       0.016358   \n",
       "3      RandomForestEntr    0.840925       0.83        0.072902       0.016415   \n",
       "4              LightGBM    0.839799       0.85        0.011799       0.002591   \n",
       "5   WeightedEnsemble_L2    0.839799       0.85        0.014085       0.002865   \n",
       "6            LightGBMXT    0.836421       0.83        0.005686       0.003748   \n",
       "7        ExtraTreesGini    0.834374       0.82        0.103416       0.016779   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.095408       0.016200   \n",
       "9         LightGBMLarge    0.828949       0.83        0.015563       0.002476   \n",
       "10       NeuralNetTorch    0.824035       0.84        0.035858       0.005727   \n",
       "11      NeuralNetFastAI    0.823626       0.82        0.070544       0.005454   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.006737       0.003972   \n",
       "13       KNeighborsDist    0.695158       0.65        0.008413       0.004278   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.604667                 0.008821                0.001961   \n",
       "1   0.127821                 0.018567                0.002214   \n",
       "2   0.220086                 0.098795                0.016358   \n",
       "3   0.201911                 0.072902                0.016415   \n",
       "4   0.289338                 0.011799                0.002591   \n",
       "5   0.456426                 0.002286                0.000274   \n",
       "6   0.169393                 0.005686                0.003748   \n",
       "7   0.178069                 0.103416                0.016779   \n",
       "8   0.194355                 0.095408                0.016200   \n",
       "9   0.519117                 0.015563                0.002476   \n",
       "10  0.590476                 0.035858                0.005727   \n",
       "11  0.289229                 0.070544                0.005454   \n",
       "12  0.003094                 0.006737                0.003972   \n",
       "13  0.003599                 0.008413                0.004278   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.604667            1       True          7  \n",
       "1            0.127821            1       True         11  \n",
       "2            0.220086            1       True          5  \n",
       "3            0.201911            1       True          6  \n",
       "4            0.289338            1       True          4  \n",
       "5            0.167088            2       True         14  \n",
       "6            0.169393            1       True          3  \n",
       "7            0.178069            1       True          8  \n",
       "8            0.194355            1       True          9  \n",
       "9            0.519117            1       True         13  \n",
       "10           0.590476            1       True         12  \n",
       "11           0.289229            1       True         10  \n",
       "12           0.003094            1       True          1  \n",
       "13           0.003599            1       True          2  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_clone.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52a77f-7dcf-43d2-8ee1-895fbbbb7c6d",
   "metadata": {},
   "source": [
    "### extra logic with the clone, such as refit_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7aef47b3-4295-46b2-81c3-9b1260f442c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_FULL ...\n",
      "\t0.01s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_FULL ...\n",
      "\t0.0s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_FULL ...\n",
      "\t0.13s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_FULL ...\n",
      "\t0.14s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestGini_FULL ...\n",
      "\t0.22s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestEntr_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_FULL ...\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesGini_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesEntr_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_FULL ...\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_FULL ...\n",
      "\t0.65s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 2.31s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_FULL</td>\n",
       "      <td>0.844303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_FULL</td>\n",
       "      <td>0.842870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_FULL</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135045</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135045</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302133</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167088</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini_FULL</td>\n",
       "      <td>0.840618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>0.066347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.014630</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.456426</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.167088</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestEntr_FULL</td>\n",
       "      <td>0.839185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.184674</td>\n",
       "      <td>0.063110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.184674</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBMXT_FULL</td>\n",
       "      <td>0.837957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129833</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129833</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExtraTreesEntr_FULL</td>\n",
       "      <td>0.835295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185813</td>\n",
       "      <td>0.072292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185813</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ExtraTreesGini_FULL</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182588</td>\n",
       "      <td>0.069058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182588</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.067081</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>0.067081</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.067029</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.067029</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.824035</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBMLarge_FULL</td>\n",
       "      <td>0.820964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210160</td>\n",
       "      <td>0.016650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210160</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NeuralNetTorch_FULL</td>\n",
       "      <td>0.818200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649799</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649799</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NeuralNetFastAI_FULL</td>\n",
       "      <td>0.769270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177114</td>\n",
       "      <td>0.049859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177114</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsUnif_FULL</td>\n",
       "      <td>0.725151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsDist_FULL</td>\n",
       "      <td>0.685434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.006833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val  pred_time_test  \\\n",
       "0               XGBoost_FULL    0.844303        NaN        0.014524   \n",
       "1              CatBoost_FULL    0.842870        NaN        0.007530   \n",
       "2                   CatBoost    0.842461       0.85        0.007651   \n",
       "3                    XGBoost    0.842461       0.85        0.016113   \n",
       "4           RandomForestGini    0.842461       0.84        0.066654   \n",
       "5           RandomForestEntr    0.840925       0.83        0.063920   \n",
       "6              LightGBM_FULL    0.840823        NaN        0.014992   \n",
       "7   WeightedEnsemble_L2_FULL    0.840823        NaN        0.016161   \n",
       "8      RandomForestGini_FULL    0.840618        NaN        0.066347   \n",
       "9                   LightGBM    0.839799       0.85        0.013693   \n",
       "10       WeightedEnsemble_L2    0.839799       0.85        0.014630   \n",
       "11     RandomForestEntr_FULL    0.839185        NaN        0.063110   \n",
       "12           LightGBMXT_FULL    0.837957        NaN        0.005100   \n",
       "13                LightGBMXT    0.836421       0.83        0.005625   \n",
       "14       ExtraTreesEntr_FULL    0.835295        NaN        0.072292   \n",
       "15       ExtraTreesGini_FULL    0.834783        NaN        0.069058   \n",
       "16            ExtraTreesGini    0.834374       0.82        0.067081   \n",
       "17            ExtraTreesEntr    0.832839       0.81        0.067029   \n",
       "18             LightGBMLarge    0.828949       0.83        0.017433   \n",
       "19            NeuralNetTorch    0.824035       0.84        0.028352   \n",
       "20           NeuralNetFastAI    0.823626       0.82        0.054527   \n",
       "21        LightGBMLarge_FULL    0.820964        NaN        0.016650   \n",
       "22       NeuralNetTorch_FULL    0.818200        NaN        0.029432   \n",
       "23      NeuralNetFastAI_FULL    0.769270        NaN        0.049859   \n",
       "24            KNeighborsUnif    0.725970       0.73        0.008095   \n",
       "25       KNeighborsUnif_FULL    0.725151        NaN        0.006310   \n",
       "26            KNeighborsDist    0.695158       0.65        0.005718   \n",
       "27       KNeighborsDist_FULL    0.685434        NaN        0.006833   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0             NaN  0.037782                 0.014524                     NaN   \n",
       "1             NaN  0.015589                 0.007530                     NaN   \n",
       "2        0.001961  0.604667                 0.007651                0.001961   \n",
       "3        0.002214  0.127821                 0.016113                0.002214   \n",
       "4        0.016358  0.220086                 0.066654                0.016358   \n",
       "5        0.016415  0.201911                 0.063920                0.016415   \n",
       "6             NaN  0.135045                 0.014992                     NaN   \n",
       "7             NaN  0.302133                 0.001169                     NaN   \n",
       "8             NaN  0.220644                 0.066347                     NaN   \n",
       "9        0.002591  0.289338                 0.013693                0.002591   \n",
       "10       0.002865  0.456426                 0.000937                0.000274   \n",
       "11            NaN  0.184674                 0.063110                     NaN   \n",
       "12            NaN  0.129833                 0.005100                     NaN   \n",
       "13       0.003748  0.169393                 0.005625                0.003748   \n",
       "14            NaN  0.185813                 0.072292                     NaN   \n",
       "15            NaN  0.182588                 0.069058                     NaN   \n",
       "16       0.016779  0.178069                 0.067081                0.016779   \n",
       "17       0.016200  0.194355                 0.067029                0.016200   \n",
       "18       0.002476  0.519117                 0.017433                0.002476   \n",
       "19       0.005727  0.590476                 0.028352                0.005727   \n",
       "20       0.005454  0.289229                 0.054527                0.005454   \n",
       "21            NaN  0.210160                 0.016650                     NaN   \n",
       "22            NaN  0.649799                 0.029432                     NaN   \n",
       "23            NaN  0.177114                 0.049859                     NaN   \n",
       "24       0.003972  0.003094                 0.008095                0.003972   \n",
       "25            NaN  0.008460                 0.006310                     NaN   \n",
       "26       0.004278  0.003599                 0.005718                0.004278   \n",
       "27            NaN  0.002492                 0.006833                     NaN   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.037782            1       True         25  \n",
       "1            0.015589            1       True         21  \n",
       "2            0.604667            1       True          7  \n",
       "3            0.127821            1       True         11  \n",
       "4            0.220086            1       True          5  \n",
       "5            0.201911            1       True          6  \n",
       "6            0.135045            1       True         18  \n",
       "7            0.167088            2       True         28  \n",
       "8            0.220644            1       True         19  \n",
       "9            0.289338            1       True          4  \n",
       "10           0.167088            2       True         14  \n",
       "11           0.184674            1       True         20  \n",
       "12           0.129833            1       True         17  \n",
       "13           0.169393            1       True          3  \n",
       "14           0.185813            1       True         23  \n",
       "15           0.182588            1       True         22  \n",
       "16           0.178069            1       True          8  \n",
       "17           0.194355            1       True          9  \n",
       "18           0.519117            1       True         13  \n",
       "19           0.590476            1       True         12  \n",
       "20           0.289229            1       True         10  \n",
       "21           0.210160            1       True         27  \n",
       "22           0.649799            1       True         26  \n",
       "23           0.177114            1       True         24  \n",
       "24           0.003094            1       True          1  \n",
       "25           0.008460            1       True         15  \n",
       "26           0.003599            1       True          2  \n",
       "27           0.002492            1       True         16  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_clone.refit_full()\n",
    "\n",
    "predictor_clone.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "753d6b24-fe4d-457f-91de-bb5bf102cb80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.099076</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>0.099076</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.220086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.081861</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>0.081861</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.456426</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.167088</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.078354</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>0.078354</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.084106</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.084106</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.519117</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.824035</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.030202</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.030202</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.057213</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>0.057213</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.289229</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              CatBoost    0.842461       0.85        0.008566       0.001961   \n",
       "1               XGBoost    0.842461       0.85        0.020118       0.002214   \n",
       "2      RandomForestGini    0.842461       0.84        0.099076       0.016358   \n",
       "3      RandomForestEntr    0.840925       0.83        0.081861       0.016415   \n",
       "4              LightGBM    0.839799       0.85        0.012930       0.002591   \n",
       "5   WeightedEnsemble_L2    0.839799       0.85        0.014183       0.002865   \n",
       "6            LightGBMXT    0.836421       0.83        0.011955       0.003748   \n",
       "7        ExtraTreesGini    0.834374       0.82        0.078354       0.016779   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.084106       0.016200   \n",
       "9         LightGBMLarge    0.828949       0.83        0.017703       0.002476   \n",
       "10       NeuralNetTorch    0.824035       0.84        0.030202       0.005727   \n",
       "11      NeuralNetFastAI    0.823626       0.82        0.057213       0.005454   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.010345       0.003972   \n",
       "13       KNeighborsDist    0.695158       0.65        0.011871       0.004278   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.604667                 0.008566                0.001961   \n",
       "1   0.127821                 0.020118                0.002214   \n",
       "2   0.220086                 0.099076                0.016358   \n",
       "3   0.201911                 0.081861                0.016415   \n",
       "4   0.289338                 0.012930                0.002591   \n",
       "5   0.456426                 0.001253                0.000274   \n",
       "6   0.169393                 0.011955                0.003748   \n",
       "7   0.178069                 0.078354                0.016779   \n",
       "8   0.194355                 0.084106                0.016200   \n",
       "9   0.519117                 0.017703                0.002476   \n",
       "10  0.590476                 0.030202                0.005727   \n",
       "11  0.289229                 0.057213                0.005454   \n",
       "12  0.003094                 0.010345                0.003972   \n",
       "13  0.003599                 0.011871                0.004278   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.604667            1       True          7  \n",
       "1            0.127821            1       True         11  \n",
       "2            0.220086            1       True          5  \n",
       "3            0.201911            1       True          6  \n",
       "4            0.289338            1       True          4  \n",
       "5            0.167088            2       True         14  \n",
       "6            0.169393            1       True          3  \n",
       "7            0.178069            1       True          8  \n",
       "8            0.194355            1       True          9  \n",
       "9            0.519117            1       True         13  \n",
       "10           0.590476            1       True         12  \n",
       "11           0.289229            1       True         10  \n",
       "12           0.003094            1       True          1  \n",
       "13           0.003599            1       True          2  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be901d-e02e-4f4a-aec1-957a4c9dbd4a",
   "metadata": {},
   "source": [
    "predictor_clone  original predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e1acd-5c9f-4411-ba08-ea0f7ff81021",
   "metadata": {},
   "source": [
    "### Snapshot a deployment optimized Predictor via .clone_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a974a4a1-5b0d-42c2-ba56-ea0a5cb5de22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloned TabularPredictor located in 'agModels-predictClass-deployment/' to 'agModels-predictClass-deployment-clone-opt'.\n",
      "\tTo load the cloned predictor: predictor_clone = TabularPredictor.load(path=\"agModels-predictClass-deployment-clone-opt\")\n",
      "Clone: Keeping minimum set of models required to predict with best model 'WeightedEnsemble_L2'...\n",
      "Deleting model KNeighborsUnif. All files under agModels-predictClass-deployment-clone-opt/models/KNeighborsUnif/ will be removed.\n",
      "Deleting model KNeighborsDist. All files under agModels-predictClass-deployment-clone-opt/models/KNeighborsDist/ will be removed.\n",
      "Deleting model LightGBMXT. All files under agModels-predictClass-deployment-clone-opt/models/LightGBMXT/ will be removed.\n",
      "Deleting model RandomForestGini. All files under agModels-predictClass-deployment-clone-opt/models/RandomForestGini/ will be removed.\n",
      "Deleting model RandomForestEntr. All files under agModels-predictClass-deployment-clone-opt/models/RandomForestEntr/ will be removed.\n",
      "Deleting model CatBoost. All files under agModels-predictClass-deployment-clone-opt/models/CatBoost/ will be removed.\n",
      "Deleting model ExtraTreesGini. All files under agModels-predictClass-deployment-clone-opt/models/ExtraTreesGini/ will be removed.\n",
      "Deleting model ExtraTreesEntr. All files under agModels-predictClass-deployment-clone-opt/models/ExtraTreesEntr/ will be removed.\n",
      "Deleting model NeuralNetFastAI. All files under agModels-predictClass-deployment-clone-opt/models/NeuralNetFastAI/ will be removed.\n",
      "Deleting model XGBoost. All files under agModels-predictClass-deployment-clone-opt/models/XGBoost/ will be removed.\n",
      "Deleting model NeuralNetTorch. All files under agModels-predictClass-deployment-clone-opt/models/NeuralNetTorch/ will be removed.\n",
      "Deleting model LightGBMLarge. All files under agModels-predictClass-deployment-clone-opt/models/LightGBMLarge/ will be removed.\n",
      "Clone: Removing artifacts unnecessary for prediction. NOTE: Clone can no longer fit new models, and most functionality except for predict and predict_proba will no longer work\n"
     ]
    }
   ],
   "source": [
    "save_path_clone_opt = save_path + '-clone-opt'\n",
    "# will return the path to the cloned predictor, identical to save_path_clone_opt\n",
    "path_clone_opt = predictor.clone_for_deployment(path=save_path_clone_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6ab5a25a-bce2-43f2-8291-e139098cf6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_clone_opt = TabularPredictor.load(path=path_clone_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "234a9d53-112f-47ae-83ed-0cc2a21a9e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting 2 models in memory. Models will require 0.0% of memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WeightedEnsemble_L2', 'LightGBM']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#         \n",
    "predictor_clone_opt.persist_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0417f85d-e31f-4eac-b9c2-6c4942cf0667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2         >50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_clone_opt = predictor_clone_opt.predict(test_data)\n",
    "y_pred_clone_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3e9cbc7c-2d83-4fcd-a16b-4713c855ac3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.equals(y_pred_clone_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aaf2b5c5-592b-482f-b984-4d73707ee268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.456426</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.167088</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0             LightGBM    0.839799       0.85        0.012381       0.002591   \n",
       "1  WeightedEnsemble_L2    0.839799       0.85        0.012951       0.002865   \n",
       "\n",
       "   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  0.289338                 0.012381                0.002591   \n",
       "1  0.456426                 0.000570                0.000274   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.289338            1       True          1  \n",
       "1           0.167088            2       True          2  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_clone_opt.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f7cbef9d-8cac-45b4-b0ca-3f5db75b2801",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Original:  16850372 bytes\n",
      "Size Optimized: 179266 bytes\n",
      "Optimized predictor achieved a 98.9% reduction in disk usage.\n"
     ]
    }
   ],
   "source": [
    "size_original = predictor.get_size_disk()\n",
    "size_opt = predictor_clone_opt.get_size_disk()\n",
    "print(f'Size Original:  {size_original} bytes')\n",
    "print(f'Size Optimized: {size_opt} bytes')\n",
    "print(f'Optimized predictor achieved a {round((1 - (size_opt/size_original)) * 100, 1)}% reduction in disk usage.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed7bf7e3-b7b9-4b52-a3f5-74cb713adac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models/ExtraTreesGini/model.pkl                        4559843\n",
       "models/ExtraTreesEntr/model.pkl                        4531477\n",
       "models/RandomForestGini/model.pkl                      3075072\n",
       "models/RandomForestEntr/model.pkl                      2951194\n",
       "models/LightGBMLarge/model.pkl                          470889\n",
       "models/XGBoost/xgb.ubj                                  454178\n",
       "models/NeuralNetTorch/model.pkl                         252021\n",
       "models/NeuralNetFastAI/model-internals.pkl              167374\n",
       "models/LightGBM/model.pkl                               146038\n",
       "models/LightGBMXT/model.pkl                              42071\n",
       "models/KNeighborsDist/model.pkl                          39986\n",
       "models/KNeighborsUnif/model.pkl                          39985\n",
       "utils/data/X.pkl                                         27655\n",
       "models/CatBoost/model.pkl                                21714\n",
       "metadata.json                                            10979\n",
       "learner.pkl                                              10728\n",
       "utils/data/X_val.pkl                                      8421\n",
       "models/WeightedEnsemble_L2/model.pkl                      8121\n",
       "utils/data/y.pkl                                          7488\n",
       "models/XGBoost/model.pkl                                  5249\n",
       "models/trainer.pkl                                        5170\n",
       "models/NeuralNetFastAI/model.pkl                          2653\n",
       "utils/data/y_val.pkl                                      2381\n",
       "models/WeightedEnsemble_L2/utils/model_template.pkl       1024\n",
       "models/WeightedEnsemble_L2/utils/oof.pkl                   764\n",
       "predictor.pkl                                              742\n",
       "utils/attr/KNeighborsUnif/y_pred_proba_val.pkl             550\n",
       "utils/attr/ExtraTreesGini/y_pred_proba_val.pkl             550\n",
       "utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl            550\n",
       "utils/attr/LightGBMLarge/y_pred_proba_val.pkl              550\n",
       "utils/attr/RandomForestEntr/y_pred_proba_val.pkl           550\n",
       "utils/attr/XGBoost/y_pred_proba_val.pkl                    550\n",
       "utils/attr/CatBoost/y_pred_proba_val.pkl                   550\n",
       "utils/attr/KNeighborsDist/y_pred_proba_val.pkl             550\n",
       "utils/attr/RandomForestGini/y_pred_proba_val.pkl           550\n",
       "utils/attr/NeuralNetTorch/y_pred_proba_val.pkl             550\n",
       "utils/attr/LightGBMXT/y_pred_proba_val.pkl                 550\n",
       "utils/attr/LightGBM/y_pred_proba_val.pkl                   550\n",
       "utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl             550\n",
       "__version__                                                  5\n",
       "Name: size, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_size_disk_per_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "74025927-bdc8-451f-ba93-424490919901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models/LightGBM/model.pkl               146065\n",
       "metadata.json                            10979\n",
       "learner.pkl                              10728\n",
       "models/WeightedEnsemble_L2/model.pkl      8285\n",
       "models/trainer.pkl                        2462\n",
       "predictor.pkl                              742\n",
       "__version__                                  5\n",
       "Name: size, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_clone_opt.get_size_disk_per_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72186a-6fbe-41f9-8f27-dfa145612419",
   "metadata": {},
   "source": [
    "### Compile models for maximized inference speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "52040189-c003-45b9-ac8e-9e8a7454e174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling 2 Models ...\n",
      "Skipping compilation for WeightedEnsemble_L2 ... (No config specified)\n",
      "Skipping compilation for LightGBM ... (No config specified)\n",
      "Finished compiling models, total runtime = 0s.\n"
     ]
    }
   ],
   "source": [
    "predictor_clone_opt.compile_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2d6c905b-41a8-4343-b244-f4f028b46bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2         >50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_compile_opt = predictor_clone_opt.predict(test_data)\n",
    "y_pred_compile_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975b65d-104f-4361-b97e-427f04022bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dct",
   "language": "python",
   "name": "dct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
